{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W9pOCWgh8Sw7"
   },
   "outputs": [],
   "source": [
    "path=r'C:/Users/lenovo/Desktop/[DM] Group Project/Data-Mining-Project-master/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dP6ftkHZ9jCE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FQiSVjyj9luT"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+\"train.csv\")\n",
    "test = pd.read_csv(path+\"test.csv\")\n",
    "labels = pd.read_csv(path+\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "C1PUU_z_9pCR",
    "outputId": "dd5de290-35b9-4ca3-80c2-86534dbbcd7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGUw11rI9q7S",
    "outputId": "6bd02d6a-ed6a-4a45-a8a5-22c8e61ab59f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id               False\n",
       " comment_text     False\n",
       " toxic            False\n",
       " severe_toxic     False\n",
       " obscene          False\n",
       " threat           False\n",
       " insult           False\n",
       " identity_hate    False\n",
       " dtype: bool, id              False\n",
       " comment_text    False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any(),test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NLlO7GHAFu6-"
   },
   "outputs": [],
   "source": [
    "classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[classes].values\n",
    "list_sentences_train = train[\"comment_text\"]\n",
    "list_sentences_test = test[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s05dhgB-FiWX"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6baQPSdkFnEo"
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0pRrAJ7pFxmX"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences    #用于填充序列为maxlen：keras只能接受长度相同的序列输入。因此如果目前序列长度参差不齐，这时需要使用pad_sequences()。该函数是将序列转化为经过填充以后的一个长度相同的新序列新序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UREu7LA_F4lU"
   },
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)    #train set\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)    #test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TMYlPdC4JzXL"
   },
   "outputs": [],
   "source": [
    "gl_path = r'C:/Users/lenovo/Desktop/[DM] Group Project/glove.twitter.27B.25d.txt'\n",
    "ft_path = r'C:/Users/lenovo/Desktop/[DM] Group Project/wiki.simple.vec'\n",
    "wv_path = r'C:/Users/lenovo/Desktop/[DM] Group Project/model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hZsMt6ihHS4i"
   },
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jHtWe2E1F7BB"
   },
   "outputs": [],
   "source": [
    "def loadEmbeddingMatrix(typeToLoad):    #to load all 3 types of embedding matrix\n",
    "        if(typeToLoad==\"glove\"):\n",
    "            EMBEDDING_FILE=gl_path\n",
    "            embed_size = 25\n",
    "        elif(typeToLoad==\"word2vec\"):\n",
    "            word2vecDict = word2vec.KeyedVectors.load_word2vec_format(wv_path, binary=True)\n",
    "            embed_size = 300\n",
    "        elif(typeToLoad==\"fasttext\"):\n",
    "            EMBEDDING_FILE=ft_path\n",
    "            embed_size = 300\n",
    "\n",
    "        if(typeToLoad==\"glove\" or typeToLoad==\"fasttext\" ):\n",
    "            embeddings_index = dict()\n",
    "            f = open(EMBEDDING_FILE, encoding='gb18030', errors='ignore')\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')            \n",
    "                if len(coefs) != 25:\n",
    "                    continue\n",
    "                embeddings_index[word] = coefs\n",
    "                \n",
    "            f.close()\n",
    "            print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "        else:\n",
    "            embeddings_index = dict()\n",
    "            for word in word2vecDict.wv.vocab:\n",
    "                embeddings_index[word] = word2vecDict.word_vec(word)\n",
    "            print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "            \n",
    "        gc.collect()\n",
    "        all_embs = np.stack(list(embeddings_index.values()))\n",
    "        emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "        \n",
    "        nb_words = len(tokenizer.word_index)\n",
    "        embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "        gc.collect()\n",
    "\n",
    "        embeddedCount = 0\n",
    "        for word, i in tokenizer.word_index.items():\n",
    "            i-=1\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None: \n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                embeddedCount+=1\n",
    "        print('total embedded:',embeddedCount,'common words')\n",
    "        \n",
    "        del(embeddings_index)\n",
    "        gc.collect()\n",
    "        \n",
    "        return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_LCBxmSEW95",
    "outputId": "9a1e55a8-0929-44a5-e9bc-31c4b62e9e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1175734 word vectors.\n",
      "total embedded: 79113 common words\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = loadEmbeddingMatrix('glove')    #load 'glove' embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "XxN-0Icgbp5h"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "BcdmD1FnbiRl"
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen, ))#Define a keras Input tensor  #Start here, configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cakxu8f2b1yY",
    "outputId": "0ecf9e11-8b57-4882-978b-8bedeb9f410c"
   },
   "outputs": [],
   "source": [
    "x = Embedding(len(tokenizer.word_index), embedding_matrix.shape[1],weights=[embedding_matrix],trainable=False)(inp)    #Convert a positive integer (index value) to a dense vector of fixed size\n",
    "x = Bidirectional(LSTM(60, return_sequences=True,name='lstm_layer',dropout=0.1,recurrent_dropout=0.1))(x)    #Realize the bidirectional structure of RNN type neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DZaoNGqdbr96"
   },
   "outputs": [],
   "source": [
    "#config the output of the model:\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "PHhVSB7LelmI"
   },
   "outputs": [],
   "source": [
    "import keras.metrics as metrics    #Neural Network Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "PoeXgv3ZcGaF"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=x)    #Define the model here (have not entered the training set for training yet) (end configuring the model)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[    #Use MSE and AUC as evaluation indicators\n",
    "                          metrics.MeanSquaredError(),\n",
    "                          metrics.AUC(),\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PW7dB94TcHw_",
    "outputId": "43cca106-5111-4b1a-d60e-ef30aa24fc50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 200, 25)           5258425   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 200, 120)         41280     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 120)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                6050      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 306       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,306,061\n",
      "Trainable params: 47,636\n",
      "Non-trainable params: 5,258,425\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xTcX5FYvmZHA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split    #spilt train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_t,y,test_size=0.2,random_state=1)     #use the x,y of the original train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ysgA5zncJqG",
    "outputId": "64f228eb-0709-4692-e3dc-4c612308871e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "998/998 [==============================] - 903s 901ms/step - loss: 0.1326 - mean_squared_error: 0.0333 - auc: 0.8169\n",
      "Epoch 2/2\n",
      "998/998 [==============================] - 926s 928ms/step - loss: 0.1034 - mean_squared_error: 0.0267 - auc: 0.9002\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 2\n",
    "hist = model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs)    #train the model using the train set (x and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "IJdnXFKp1uO1"
   },
   "outputs": [],
   "source": [
    "preds_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3623595e-02, 3.2344460e-04, 4.4855177e-03, 1.6424060e-04,\n",
       "        3.4399033e-03, 7.5829029e-04],\n",
       "       [1.2687048e-01, 7.4063241e-03, 4.7938168e-02, 4.2207539e-03,\n",
       "        4.8898876e-02, 9.8959208e-03],\n",
       "       [2.3175627e-02, 6.0126185e-04, 6.1507821e-03, 3.2186508e-04,\n",
       "        6.3243210e-03, 1.5035570e-03],\n",
       "       ...,\n",
       "       [8.4456414e-02, 1.0075003e-02, 4.3412924e-02, 4.4140816e-03,\n",
       "        3.7735641e-02, 1.2299478e-02],\n",
       "       [6.2018305e-02, 5.3495765e-03, 2.9902428e-02, 2.2993088e-03,\n",
       "        2.4940401e-02, 7.1427524e-03],\n",
       "       [3.0706561e-01, 3.6669910e-02, 1.7276996e-01, 9.9048018e-03,\n",
       "        1.7223799e-01, 2.0926386e-02]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcujEmttF9YV",
    "outputId": "cd59c66d-7863-414b-dfe8-4c837fcdf3da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908518351978887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "\n",
    "print(roc_auc_score(y_train, preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "FVUhIPBGGQpv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8961344328164914\n"
     ]
    }
   ],
   "source": [
    "preds_val = model.predict(X_val)\n",
    "print(roc_auc_score(y_val, preds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1290977e-01, 8.0278933e-02, 3.0935419e-01, 2.8832287e-02,\n",
       "        3.5673428e-01, 4.9698800e-02],\n",
       "       [1.1185366e-01, 2.6380420e-03, 3.7509620e-02, 1.7556846e-03,\n",
       "        3.7862450e-02, 6.6973865e-03],\n",
       "       [2.2268474e-02, 5.0884485e-04, 6.5262318e-03, 2.7891994e-04,\n",
       "        5.3603649e-03, 1.1652410e-03],\n",
       "       ...,\n",
       "       [7.6115519e-02, 7.2779655e-03, 3.8205326e-02, 3.4002960e-03,\n",
       "        2.9074788e-02, 1.0733515e-02],\n",
       "       [5.7007879e-02, 5.3457320e-03, 2.6141226e-02, 2.0368695e-03,\n",
       "        2.1537781e-02, 6.8677366e-03],\n",
       "       [2.9756570e-01, 2.3902565e-02, 1.3929316e-01, 1.1374146e-02,\n",
       "        1.5674523e-01, 2.4024814e-02]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "VTEKRPU8GR_-"
   },
   "outputs": [],
   "source": [
    "labels = labels[classes]\n",
    "sum_labels=np.sum(labels.values,axis=1)\n",
    "# print(sum_labels)\n",
    "idx=sum_labels>=0\n",
    "y_test = labels[idx]\n",
    "X_test = X_te[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "dbNiGXHuGYpq"
   },
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)    #predict using the test's x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojrhEz03GcM2",
    "outputId": "a84bfcf4-b7f1-4c74-eaa7-865ab659513c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8731585814602864\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, preds_test))    #test accuracy for 'glove'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTM-glove.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
