{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"bili_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train['comment_text'],train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']], test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "symbols = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return symbols.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ml_xi\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transform_function = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1).fit(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train = transform_function.transform(train_x)\n",
    "comments_val = transform_function.transform(val_x)\n",
    "comments_test = transform_function.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(train_x)\n",
    "val_x = pd.DataFrame(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [train_x, val_x, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['total_length', 'capitals', 'caps_vs_length','num_exclamation_marks', 'num_question_marks', 'num_punctuation','num_symbols', 'num_words', 'num_unique_words', 'words_vs_unique','num_smilies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in combined:\n",
    "    data['total_length'] = data['comment_text'].apply(len)\n",
    "    data['capitals'] = data['comment_text'].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "    data['caps_vs_length'] = data.apply(lambda row: float(row['capitals'])/float(row['total_length']),\n",
    "                                axis=1)\n",
    "    data['num_exclamation_marks'] = data['comment_text'].apply(lambda x: x.count('!'))\n",
    "    data['num_question_marks'] = data['comment_text'].apply(lambda x: x.count('?'))\n",
    "    data['num_punctuation'] = data['comment_text'].apply(lambda x: sum(x.count(w) for w in '.,;:'))\n",
    "    data['num_symbols'] = data['comment_text'].apply(lambda x: sum(x.count(w) for w in '*&$%'))\n",
    "    data['num_words'] = data['comment_text'].apply(lambda x: len(x.split()))\n",
    "    data['num_unique_words'] = data['comment_text'].apply(lambda x: len(set(w for w in x.split())))\n",
    "    data['words_vs_unique'] = data['num_unique_words'] / data['num_words']\n",
    "    data['num_smilies'] = data['comment_text'].apply(lambda x: sum(x.count(w) for w in (':-)', ':)', ';-)', ';)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "train_x = scipy.sparse.csr_matrix(train_x[col].values)\n",
    "val_x = scipy.sparse.csr_matrix(val_x[col].values)\n",
    "test = scipy.sparse.csr_matrix(test[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train = scipy.sparse.hstack([train_x.tocsr(),comments_train.tocsr()])\n",
    "comments_val = scipy.sparse.hstack([val_x,comments_val])\n",
    "comments_test = scipy.sparse.hstack([test,comments_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_X, train_y, test_X, test_y=None, feature_names=None):\n",
    "    dic = {}\n",
    "    dic['objective'] = 'binary:logistic'\n",
    "    dic['eta'] = 0.1\n",
    "    dic['max_depth'] = 6\n",
    "    dic['silent'] = 1\n",
    "    dic['eval_metric'] = 'auc'\n",
    "    dic['min_child_weight'] = 1\n",
    "    dic['subsample'] = 0.7\n",
    "    dic['colsample_bytree'] = 0.7\n",
    "    num = 100\n",
    "    list_dic = list(dic.items())\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "\n",
    "    model = xgb.train(list_dic, xgtrain, num, [ (xgtrain,'train'), (xgtest, 'test') ], early_stopping_rounds=10)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "[20:12:23] WARNING: D:\\Build\\xgboost\\xgboost-1.5.1.git\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.69918\ttest-auc:0.69861\n",
      "[1]\ttrain-auc:0.71597\ttest-auc:0.71605\n",
      "[2]\ttrain-auc:0.75598\ttest-auc:0.75801\n",
      "[3]\ttrain-auc:0.76397\ttest-auc:0.76431\n",
      "[4]\ttrain-auc:0.76690\ttest-auc:0.76740\n",
      "[5]\ttrain-auc:0.82699\ttest-auc:0.82094\n",
      "[6]\ttrain-auc:0.85755\ttest-auc:0.84995\n",
      "[7]\ttrain-auc:0.85698\ttest-auc:0.85013\n",
      "[8]\ttrain-auc:0.85867\ttest-auc:0.85116\n",
      "[9]\ttrain-auc:0.86382\ttest-auc:0.85564\n",
      "[10]\ttrain-auc:0.87147\ttest-auc:0.86218\n",
      "[11]\ttrain-auc:0.87592\ttest-auc:0.86619\n",
      "[12]\ttrain-auc:0.88396\ttest-auc:0.87416\n",
      "[13]\ttrain-auc:0.88761\ttest-auc:0.87731\n",
      "[14]\ttrain-auc:0.89162\ttest-auc:0.88209\n",
      "[15]\ttrain-auc:0.89253\ttest-auc:0.88239\n",
      "[16]\ttrain-auc:0.89931\ttest-auc:0.89070\n",
      "[17]\ttrain-auc:0.90224\ttest-auc:0.89345\n",
      "[18]\ttrain-auc:0.90466\ttest-auc:0.89581\n",
      "[19]\ttrain-auc:0.90597\ttest-auc:0.89692\n",
      "[20]\ttrain-auc:0.90828\ttest-auc:0.89936\n",
      "[21]\ttrain-auc:0.91003\ttest-auc:0.90095\n",
      "[22]\ttrain-auc:0.91256\ttest-auc:0.90405\n",
      "[23]\ttrain-auc:0.91431\ttest-auc:0.90562\n",
      "[24]\ttrain-auc:0.91680\ttest-auc:0.90726\n",
      "[25]\ttrain-auc:0.91900\ttest-auc:0.90983\n",
      "[26]\ttrain-auc:0.91999\ttest-auc:0.91063\n",
      "[27]\ttrain-auc:0.92154\ttest-auc:0.91244\n",
      "[28]\ttrain-auc:0.92302\ttest-auc:0.91302\n",
      "[29]\ttrain-auc:0.92342\ttest-auc:0.91360\n",
      "[30]\ttrain-auc:0.92469\ttest-auc:0.91450\n",
      "[31]\ttrain-auc:0.92683\ttest-auc:0.91641\n",
      "[32]\ttrain-auc:0.92788\ttest-auc:0.91713\n",
      "[33]\ttrain-auc:0.92971\ttest-auc:0.91836\n",
      "[34]\ttrain-auc:0.93098\ttest-auc:0.91932\n",
      "[35]\ttrain-auc:0.93136\ttest-auc:0.91955\n",
      "[36]\ttrain-auc:0.93270\ttest-auc:0.92080\n",
      "[37]\ttrain-auc:0.93345\ttest-auc:0.92185\n",
      "[38]\ttrain-auc:0.93472\ttest-auc:0.92291\n",
      "[39]\ttrain-auc:0.93571\ttest-auc:0.92380\n",
      "[40]\ttrain-auc:0.93696\ttest-auc:0.92493\n",
      "[41]\ttrain-auc:0.93793\ttest-auc:0.92580\n",
      "[42]\ttrain-auc:0.93834\ttest-auc:0.92627\n",
      "[43]\ttrain-auc:0.93926\ttest-auc:0.92696\n",
      "[44]\ttrain-auc:0.94033\ttest-auc:0.92778\n",
      "[45]\ttrain-auc:0.94151\ttest-auc:0.92835\n",
      "[46]\ttrain-auc:0.94273\ttest-auc:0.92954\n",
      "[47]\ttrain-auc:0.94375\ttest-auc:0.93045\n",
      "[48]\ttrain-auc:0.94429\ttest-auc:0.93118\n",
      "[49]\ttrain-auc:0.94494\ttest-auc:0.93145\n",
      "[50]\ttrain-auc:0.94557\ttest-auc:0.93203\n",
      "[51]\ttrain-auc:0.94637\ttest-auc:0.93277\n",
      "[52]\ttrain-auc:0.94714\ttest-auc:0.93320\n",
      "[53]\ttrain-auc:0.94778\ttest-auc:0.93372\n",
      "[54]\ttrain-auc:0.94792\ttest-auc:0.93415\n",
      "[55]\ttrain-auc:0.94829\ttest-auc:0.93453\n",
      "[56]\ttrain-auc:0.94888\ttest-auc:0.93517\n",
      "[57]\ttrain-auc:0.94948\ttest-auc:0.93534\n",
      "[58]\ttrain-auc:0.95022\ttest-auc:0.93585\n",
      "[59]\ttrain-auc:0.95074\ttest-auc:0.93622\n",
      "[60]\ttrain-auc:0.95105\ttest-auc:0.93642\n",
      "[61]\ttrain-auc:0.95172\ttest-auc:0.93704\n",
      "[62]\ttrain-auc:0.95208\ttest-auc:0.93740\n",
      "[63]\ttrain-auc:0.95237\ttest-auc:0.93764\n",
      "[64]\ttrain-auc:0.95285\ttest-auc:0.93820\n",
      "[65]\ttrain-auc:0.95318\ttest-auc:0.93854\n",
      "[66]\ttrain-auc:0.95378\ttest-auc:0.93883\n",
      "[67]\ttrain-auc:0.95434\ttest-auc:0.93927\n",
      "[68]\ttrain-auc:0.95471\ttest-auc:0.93978\n",
      "[69]\ttrain-auc:0.95508\ttest-auc:0.94021\n",
      "[70]\ttrain-auc:0.95555\ttest-auc:0.94063\n",
      "[71]\ttrain-auc:0.95609\ttest-auc:0.94078\n",
      "[72]\ttrain-auc:0.95632\ttest-auc:0.94104\n",
      "[73]\ttrain-auc:0.95672\ttest-auc:0.94132\n",
      "[74]\ttrain-auc:0.95694\ttest-auc:0.94153\n",
      "[75]\ttrain-auc:0.95718\ttest-auc:0.94176\n",
      "[76]\ttrain-auc:0.95765\ttest-auc:0.94219\n",
      "[77]\ttrain-auc:0.95793\ttest-auc:0.94250\n",
      "[78]\ttrain-auc:0.95827\ttest-auc:0.94279\n",
      "[79]\ttrain-auc:0.95861\ttest-auc:0.94315\n",
      "[80]\ttrain-auc:0.95904\ttest-auc:0.94352\n",
      "[81]\ttrain-auc:0.95940\ttest-auc:0.94383\n",
      "[82]\ttrain-auc:0.95977\ttest-auc:0.94399\n",
      "[83]\ttrain-auc:0.96007\ttest-auc:0.94429\n",
      "[84]\ttrain-auc:0.96031\ttest-auc:0.94452\n",
      "[85]\ttrain-auc:0.96059\ttest-auc:0.94504\n",
      "[86]\ttrain-auc:0.96096\ttest-auc:0.94551\n",
      "[87]\ttrain-auc:0.96141\ttest-auc:0.94614\n",
      "[88]\ttrain-auc:0.96171\ttest-auc:0.94631\n",
      "[89]\ttrain-auc:0.96206\ttest-auc:0.94652\n",
      "[90]\ttrain-auc:0.96234\ttest-auc:0.94666\n",
      "[91]\ttrain-auc:0.96253\ttest-auc:0.94695\n",
      "[92]\ttrain-auc:0.96284\ttest-auc:0.94747\n",
      "[93]\ttrain-auc:0.96299\ttest-auc:0.94753\n",
      "[94]\ttrain-auc:0.96309\ttest-auc:0.94762\n",
      "[95]\ttrain-auc:0.96331\ttest-auc:0.94780\n",
      "[96]\ttrain-auc:0.96359\ttest-auc:0.94804\n",
      "[97]\ttrain-auc:0.96381\ttest-auc:0.94825\n",
      "[98]\ttrain-auc:0.96398\ttest-auc:0.94855\n",
      "[99]\ttrain-auc:0.96428\ttest-auc:0.94863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ml_xi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit severe_toxic\n",
      "[20:13:34] WARNING: D:\\Build\\xgboost\\xgboost-1.5.1.git\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.82168\ttest-auc:0.82789\n",
      "[1]\ttrain-auc:0.86087\ttest-auc:0.86567\n",
      "[2]\ttrain-auc:0.89183\ttest-auc:0.89292\n",
      "[3]\ttrain-auc:0.90699\ttest-auc:0.90721\n",
      "[4]\ttrain-auc:0.90909\ttest-auc:0.90863\n",
      "[5]\ttrain-auc:0.92527\ttest-auc:0.92512\n",
      "[6]\ttrain-auc:0.93603\ttest-auc:0.93043\n",
      "[7]\ttrain-auc:0.93885\ttest-auc:0.93479\n",
      "[8]\ttrain-auc:0.94392\ttest-auc:0.94437\n",
      "[9]\ttrain-auc:0.94563\ttest-auc:0.94873\n",
      "[10]\ttrain-auc:0.94608\ttest-auc:0.94896\n",
      "[11]\ttrain-auc:0.94651\ttest-auc:0.94910\n",
      "[12]\ttrain-auc:0.94659\ttest-auc:0.95054\n",
      "[13]\ttrain-auc:0.94670\ttest-auc:0.95058\n",
      "[14]\ttrain-auc:0.94716\ttest-auc:0.95047\n",
      "[15]\ttrain-auc:0.94766\ttest-auc:0.95186\n",
      "[16]\ttrain-auc:0.94845\ttest-auc:0.95598\n",
      "[17]\ttrain-auc:0.94931\ttest-auc:0.95594\n",
      "[18]\ttrain-auc:0.94967\ttest-auc:0.95744\n",
      "[19]\ttrain-auc:0.94980\ttest-auc:0.95745\n",
      "[20]\ttrain-auc:0.95182\ttest-auc:0.95747\n",
      "[21]\ttrain-auc:0.95310\ttest-auc:0.96182\n",
      "[22]\ttrain-auc:0.96446\ttest-auc:0.96638\n",
      "[23]\ttrain-auc:0.96710\ttest-auc:0.96794\n",
      "[24]\ttrain-auc:0.96934\ttest-auc:0.96762\n",
      "[25]\ttrain-auc:0.97022\ttest-auc:0.96760\n",
      "[26]\ttrain-auc:0.97031\ttest-auc:0.96761\n",
      "[27]\ttrain-auc:0.97036\ttest-auc:0.96762\n",
      "[28]\ttrain-auc:0.97098\ttest-auc:0.96751\n",
      "[29]\ttrain-auc:0.97100\ttest-auc:0.96733\n",
      "[30]\ttrain-auc:0.97097\ttest-auc:0.96732\n",
      "[31]\ttrain-auc:0.97252\ttest-auc:0.96720\n",
      "[32]\ttrain-auc:0.97519\ttest-auc:0.96991\n",
      "[33]\ttrain-auc:0.97508\ttest-auc:0.96957\n",
      "[34]\ttrain-auc:0.97622\ttest-auc:0.97085\n",
      "[35]\ttrain-auc:0.97614\ttest-auc:0.97074\n",
      "[36]\ttrain-auc:0.97939\ttest-auc:0.97248\n",
      "[37]\ttrain-auc:0.97949\ttest-auc:0.97243\n",
      "[38]\ttrain-auc:0.98007\ttest-auc:0.97190\n",
      "[39]\ttrain-auc:0.98071\ttest-auc:0.97169\n",
      "[40]\ttrain-auc:0.98452\ttest-auc:0.98075\n",
      "[41]\ttrain-auc:0.98474\ttest-auc:0.98108\n",
      "[42]\ttrain-auc:0.98482\ttest-auc:0.98100\n",
      "[43]\ttrain-auc:0.98581\ttest-auc:0.98096\n",
      "[44]\ttrain-auc:0.98589\ttest-auc:0.98099\n",
      "[45]\ttrain-auc:0.98692\ttest-auc:0.98131\n",
      "[46]\ttrain-auc:0.98745\ttest-auc:0.98188\n",
      "[47]\ttrain-auc:0.98803\ttest-auc:0.98170\n",
      "[48]\ttrain-auc:0.98859\ttest-auc:0.98187\n",
      "[49]\ttrain-auc:0.98867\ttest-auc:0.98199\n",
      "[50]\ttrain-auc:0.98878\ttest-auc:0.98208\n",
      "[51]\ttrain-auc:0.98916\ttest-auc:0.98349\n",
      "[52]\ttrain-auc:0.98970\ttest-auc:0.98356\n",
      "[53]\ttrain-auc:0.99018\ttest-auc:0.98337\n",
      "[54]\ttrain-auc:0.99017\ttest-auc:0.98334\n",
      "[55]\ttrain-auc:0.99049\ttest-auc:0.98336\n",
      "[56]\ttrain-auc:0.99069\ttest-auc:0.98366\n",
      "[57]\ttrain-auc:0.99076\ttest-auc:0.98381\n",
      "[58]\ttrain-auc:0.99081\ttest-auc:0.98356\n",
      "[59]\ttrain-auc:0.99098\ttest-auc:0.98347\n",
      "[60]\ttrain-auc:0.99118\ttest-auc:0.98357\n",
      "[61]\ttrain-auc:0.99148\ttest-auc:0.98403\n",
      "[62]\ttrain-auc:0.99162\ttest-auc:0.98446\n",
      "[63]\ttrain-auc:0.99175\ttest-auc:0.98459\n",
      "[64]\ttrain-auc:0.99184\ttest-auc:0.98444\n",
      "[65]\ttrain-auc:0.99201\ttest-auc:0.98441\n",
      "[66]\ttrain-auc:0.99215\ttest-auc:0.98445\n",
      "[67]\ttrain-auc:0.99232\ttest-auc:0.98487\n",
      "[68]\ttrain-auc:0.99251\ttest-auc:0.98476\n",
      "[69]\ttrain-auc:0.99261\ttest-auc:0.98472\n",
      "[70]\ttrain-auc:0.99261\ttest-auc:0.98470\n",
      "[71]\ttrain-auc:0.99276\ttest-auc:0.98479\n",
      "[72]\ttrain-auc:0.99288\ttest-auc:0.98494\n",
      "[73]\ttrain-auc:0.99297\ttest-auc:0.98505\n",
      "[74]\ttrain-auc:0.99300\ttest-auc:0.98501\n",
      "[75]\ttrain-auc:0.99307\ttest-auc:0.98501\n",
      "[76]\ttrain-auc:0.99317\ttest-auc:0.98525\n",
      "[77]\ttrain-auc:0.99312\ttest-auc:0.98528\n",
      "[78]\ttrain-auc:0.99325\ttest-auc:0.98528\n",
      "[79]\ttrain-auc:0.99332\ttest-auc:0.98516\n",
      "[80]\ttrain-auc:0.99339\ttest-auc:0.98516\n",
      "[81]\ttrain-auc:0.99345\ttest-auc:0.98525\n",
      "[82]\ttrain-auc:0.99353\ttest-auc:0.98537\n",
      "[83]\ttrain-auc:0.99359\ttest-auc:0.98538\n",
      "[84]\ttrain-auc:0.99369\ttest-auc:0.98540\n",
      "[85]\ttrain-auc:0.99378\ttest-auc:0.98544\n",
      "[86]\ttrain-auc:0.99383\ttest-auc:0.98551\n",
      "[87]\ttrain-auc:0.99389\ttest-auc:0.98551\n",
      "[88]\ttrain-auc:0.99394\ttest-auc:0.98542\n",
      "[89]\ttrain-auc:0.99397\ttest-auc:0.98551\n",
      "[90]\ttrain-auc:0.99401\ttest-auc:0.98552\n",
      "[91]\ttrain-auc:0.99404\ttest-auc:0.98551\n",
      "[92]\ttrain-auc:0.99411\ttest-auc:0.98549\n",
      "[93]\ttrain-auc:0.99418\ttest-auc:0.98559\n",
      "[94]\ttrain-auc:0.99425\ttest-auc:0.98547\n",
      "[95]\ttrain-auc:0.99430\ttest-auc:0.98551\n",
      "[96]\ttrain-auc:0.99436\ttest-auc:0.98548\n",
      "[97]\ttrain-auc:0.99440\ttest-auc:0.98552\n",
      "[98]\ttrain-auc:0.99443\ttest-auc:0.98548\n",
      "[99]\ttrain-auc:0.99447\ttest-auc:0.98555\n",
      "fit obscene\n",
      "[20:14:37] WARNING: D:\\Build\\xgboost\\xgboost-1.5.1.git\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.79909\ttest-auc:0.80105\n",
      "[1]\ttrain-auc:0.81261\ttest-auc:0.81233\n",
      "[2]\ttrain-auc:0.81436\ttest-auc:0.81385\n",
      "[3]\ttrain-auc:0.81498\ttest-auc:0.81424\n",
      "[4]\ttrain-auc:0.82580\ttest-auc:0.82330\n",
      "[5]\ttrain-auc:0.84204\ttest-auc:0.84084\n",
      "[6]\ttrain-auc:0.84223\ttest-auc:0.84147\n",
      "[7]\ttrain-auc:0.84785\ttest-auc:0.84450\n",
      "[8]\ttrain-auc:0.86357\ttest-auc:0.86138\n",
      "[9]\ttrain-auc:0.86396\ttest-auc:0.86189\n",
      "[10]\ttrain-auc:0.87008\ttest-auc:0.86836\n",
      "[11]\ttrain-auc:0.88891\ttest-auc:0.88347\n",
      "[12]\ttrain-auc:0.90051\ttest-auc:0.89384\n",
      "[13]\ttrain-auc:0.90153\ttest-auc:0.89511\n",
      "[14]\ttrain-auc:0.90690\ttest-auc:0.89899\n",
      "[15]\ttrain-auc:0.90698\ttest-auc:0.89909\n",
      "[16]\ttrain-auc:0.90585\ttest-auc:0.89770\n",
      "[17]\ttrain-auc:0.90973\ttest-auc:0.90057\n",
      "[18]\ttrain-auc:0.91258\ttest-auc:0.90529\n",
      "[19]\ttrain-auc:0.91292\ttest-auc:0.90568\n",
      "[20]\ttrain-auc:0.93596\ttest-auc:0.92761\n",
      "[21]\ttrain-auc:0.93789\ttest-auc:0.93028\n",
      "[22]\ttrain-auc:0.94223\ttest-auc:0.93812\n",
      "[23]\ttrain-auc:0.94432\ttest-auc:0.93995\n",
      "[24]\ttrain-auc:0.94748\ttest-auc:0.94159\n",
      "[25]\ttrain-auc:0.94913\ttest-auc:0.94224\n",
      "[26]\ttrain-auc:0.95038\ttest-auc:0.94325\n",
      "[27]\ttrain-auc:0.95247\ttest-auc:0.94315\n",
      "[28]\ttrain-auc:0.95250\ttest-auc:0.94304\n",
      "[29]\ttrain-auc:0.95881\ttest-auc:0.95160\n",
      "[30]\ttrain-auc:0.96085\ttest-auc:0.95524\n",
      "[31]\ttrain-auc:0.96268\ttest-auc:0.95595\n",
      "[32]\ttrain-auc:0.96541\ttest-auc:0.95815\n",
      "[33]\ttrain-auc:0.96565\ttest-auc:0.95883\n",
      "[34]\ttrain-auc:0.96644\ttest-auc:0.95967\n",
      "[35]\ttrain-auc:0.96683\ttest-auc:0.95975\n",
      "[36]\ttrain-auc:0.96777\ttest-auc:0.96032\n",
      "[37]\ttrain-auc:0.96859\ttest-auc:0.96092\n",
      "[38]\ttrain-auc:0.96941\ttest-auc:0.96172\n",
      "[39]\ttrain-auc:0.97049\ttest-auc:0.96195\n",
      "[40]\ttrain-auc:0.97080\ttest-auc:0.96206\n",
      "[41]\ttrain-auc:0.97120\ttest-auc:0.96235\n",
      "[42]\ttrain-auc:0.97162\ttest-auc:0.96258\n",
      "[43]\ttrain-auc:0.97220\ttest-auc:0.96293\n",
      "[44]\ttrain-auc:0.97304\ttest-auc:0.96429\n",
      "[45]\ttrain-auc:0.97373\ttest-auc:0.96502\n",
      "[46]\ttrain-auc:0.97464\ttest-auc:0.96582\n",
      "[47]\ttrain-auc:0.97463\ttest-auc:0.96578\n",
      "[48]\ttrain-auc:0.97502\ttest-auc:0.96604\n",
      "[49]\ttrain-auc:0.97545\ttest-auc:0.96648\n",
      "[50]\ttrain-auc:0.97583\ttest-auc:0.96711\n",
      "[51]\ttrain-auc:0.97618\ttest-auc:0.96736\n",
      "[52]\ttrain-auc:0.97711\ttest-auc:0.96819\n",
      "[53]\ttrain-auc:0.97741\ttest-auc:0.96826\n",
      "[54]\ttrain-auc:0.97755\ttest-auc:0.96835\n",
      "[55]\ttrain-auc:0.97796\ttest-auc:0.96871\n",
      "[56]\ttrain-auc:0.97869\ttest-auc:0.96946\n",
      "[57]\ttrain-auc:0.97891\ttest-auc:0.96944\n",
      "[58]\ttrain-auc:0.97938\ttest-auc:0.96972\n",
      "[59]\ttrain-auc:0.97962\ttest-auc:0.96992\n",
      "[60]\ttrain-auc:0.97987\ttest-auc:0.97015\n",
      "[61]\ttrain-auc:0.98018\ttest-auc:0.97063\n",
      "[62]\ttrain-auc:0.98056\ttest-auc:0.97099\n",
      "[63]\ttrain-auc:0.98073\ttest-auc:0.97112\n",
      "[64]\ttrain-auc:0.98095\ttest-auc:0.97159\n",
      "[65]\ttrain-auc:0.98109\ttest-auc:0.97172\n",
      "[66]\ttrain-auc:0.98146\ttest-auc:0.97193\n",
      "[67]\ttrain-auc:0.98196\ttest-auc:0.97208\n",
      "[68]\ttrain-auc:0.98224\ttest-auc:0.97242\n",
      "[69]\ttrain-auc:0.98246\ttest-auc:0.97266\n",
      "[70]\ttrain-auc:0.98282\ttest-auc:0.97321\n",
      "[71]\ttrain-auc:0.98317\ttest-auc:0.97303\n",
      "[72]\ttrain-auc:0.98339\ttest-auc:0.97345\n",
      "[73]\ttrain-auc:0.98352\ttest-auc:0.97357\n",
      "[74]\ttrain-auc:0.98375\ttest-auc:0.97372\n",
      "[75]\ttrain-auc:0.98404\ttest-auc:0.97381\n",
      "[76]\ttrain-auc:0.98433\ttest-auc:0.97394\n",
      "[77]\ttrain-auc:0.98453\ttest-auc:0.97424\n",
      "[78]\ttrain-auc:0.98472\ttest-auc:0.97459\n",
      "[79]\ttrain-auc:0.98494\ttest-auc:0.97484\n",
      "[80]\ttrain-auc:0.98517\ttest-auc:0.97489\n",
      "[81]\ttrain-auc:0.98548\ttest-auc:0.97514\n",
      "[82]\ttrain-auc:0.98553\ttest-auc:0.97532\n",
      "[83]\ttrain-auc:0.98582\ttest-auc:0.97544\n",
      "[84]\ttrain-auc:0.98601\ttest-auc:0.97560\n",
      "[85]\ttrain-auc:0.98616\ttest-auc:0.97562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86]\ttrain-auc:0.98631\ttest-auc:0.97609\n",
      "[87]\ttrain-auc:0.98636\ttest-auc:0.97645\n",
      "[88]\ttrain-auc:0.98651\ttest-auc:0.97655\n",
      "[89]\ttrain-auc:0.98663\ttest-auc:0.97682\n",
      "[90]\ttrain-auc:0.98668\ttest-auc:0.97692\n",
      "[91]\ttrain-auc:0.98683\ttest-auc:0.97704\n",
      "[92]\ttrain-auc:0.98696\ttest-auc:0.97709\n",
      "[93]\ttrain-auc:0.98711\ttest-auc:0.97715\n",
      "[94]\ttrain-auc:0.98734\ttest-auc:0.97725\n",
      "[95]\ttrain-auc:0.98752\ttest-auc:0.97718\n",
      "[96]\ttrain-auc:0.98755\ttest-auc:0.97722\n",
      "[97]\ttrain-auc:0.98769\ttest-auc:0.97746\n",
      "[98]\ttrain-auc:0.98786\ttest-auc:0.97759\n",
      "[99]\ttrain-auc:0.98804\ttest-auc:0.97777\n",
      "fit threat\n",
      "[20:15:48] WARNING: D:\\Build\\xgboost\\xgboost-1.5.1.git\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.69659\ttest-auc:0.73251\n",
      "[1]\ttrain-auc:0.73755\ttest-auc:0.74882\n",
      "[2]\ttrain-auc:0.74528\ttest-auc:0.74884\n",
      "[3]\ttrain-auc:0.75549\ttest-auc:0.75991\n",
      "[4]\ttrain-auc:0.76449\ttest-auc:0.75990\n",
      "[5]\ttrain-auc:0.76967\ttest-auc:0.75989\n",
      "[6]\ttrain-auc:0.78121\ttest-auc:0.77098\n",
      "[7]\ttrain-auc:0.78766\ttest-auc:0.77654\n",
      "[8]\ttrain-auc:0.80176\ttest-auc:0.77643\n",
      "[9]\ttrain-auc:0.82837\ttest-auc:0.78694\n",
      "[10]\ttrain-auc:0.82964\ttest-auc:0.79243\n",
      "[11]\ttrain-auc:0.83328\ttest-auc:0.79768\n",
      "[12]\ttrain-auc:0.84099\ttest-auc:0.81437\n",
      "[13]\ttrain-auc:0.84472\ttest-auc:0.81419\n",
      "[14]\ttrain-auc:0.84984\ttest-auc:0.81422\n",
      "[15]\ttrain-auc:0.85243\ttest-auc:0.81972\n",
      "[16]\ttrain-auc:0.85625\ttest-auc:0.82518\n",
      "[17]\ttrain-auc:0.86394\ttest-auc:0.82509\n",
      "[18]\ttrain-auc:0.87155\ttest-auc:0.83600\n",
      "[19]\ttrain-auc:0.87788\ttest-auc:0.83589\n",
      "[20]\ttrain-auc:0.88041\ttest-auc:0.84146\n",
      "[21]\ttrain-auc:0.89124\ttest-auc:0.84589\n",
      "[22]\ttrain-auc:0.89380\ttest-auc:0.84583\n",
      "[23]\ttrain-auc:0.90480\ttest-auc:0.88920\n",
      "[24]\ttrain-auc:0.91367\ttest-auc:0.89442\n",
      "[25]\ttrain-auc:0.91871\ttest-auc:0.89978\n",
      "[26]\ttrain-auc:0.92129\ttest-auc:0.90009\n",
      "[27]\ttrain-auc:0.92140\ttest-auc:0.90042\n",
      "[28]\ttrain-auc:0.92642\ttest-auc:0.90587\n",
      "[29]\ttrain-auc:0.93009\ttest-auc:0.90554\n",
      "[30]\ttrain-auc:0.93496\ttest-auc:0.91598\n",
      "[31]\ttrain-auc:0.93756\ttest-auc:0.92135\n",
      "[32]\ttrain-auc:0.94112\ttest-auc:0.92075\n",
      "[33]\ttrain-auc:0.94234\ttest-auc:0.92056\n",
      "[34]\ttrain-auc:0.94336\ttest-auc:0.92044\n",
      "[35]\ttrain-auc:0.94319\ttest-auc:0.92023\n",
      "[36]\ttrain-auc:0.94881\ttest-auc:0.93581\n",
      "[37]\ttrain-auc:0.94890\ttest-auc:0.93563\n",
      "[38]\ttrain-auc:0.95010\ttest-auc:0.93577\n",
      "[39]\ttrain-auc:0.95805\ttest-auc:0.94919\n",
      "[40]\ttrain-auc:0.97723\ttest-auc:0.96376\n",
      "[41]\ttrain-auc:0.97784\ttest-auc:0.96311\n",
      "[42]\ttrain-auc:0.97784\ttest-auc:0.96350\n",
      "[43]\ttrain-auc:0.98277\ttest-auc:0.96263\n",
      "[44]\ttrain-auc:0.98519\ttest-auc:0.95961\n",
      "[45]\ttrain-auc:0.98598\ttest-auc:0.95951\n",
      "[46]\ttrain-auc:0.98579\ttest-auc:0.96005\n",
      "[47]\ttrain-auc:0.98600\ttest-auc:0.96579\n",
      "[48]\ttrain-auc:0.98635\ttest-auc:0.96541\n",
      "[49]\ttrain-auc:0.98623\ttest-auc:0.96503\n",
      "[50]\ttrain-auc:0.98730\ttest-auc:0.96278\n",
      "[51]\ttrain-auc:0.98746\ttest-auc:0.96247\n",
      "[52]\ttrain-auc:0.98772\ttest-auc:0.96240\n",
      "[53]\ttrain-auc:0.98822\ttest-auc:0.97216\n",
      "[54]\ttrain-auc:0.98850\ttest-auc:0.97198\n",
      "[55]\ttrain-auc:0.98862\ttest-auc:0.97126\n",
      "[56]\ttrain-auc:0.98867\ttest-auc:0.97052\n",
      "[57]\ttrain-auc:0.98863\ttest-auc:0.97013\n",
      "[58]\ttrain-auc:0.99016\ttest-auc:0.97090\n",
      "[59]\ttrain-auc:0.99056\ttest-auc:0.97032\n",
      "[60]\ttrain-auc:0.99123\ttest-auc:0.96989\n",
      "[61]\ttrain-auc:0.99272\ttest-auc:0.97122\n",
      "[62]\ttrain-auc:0.99286\ttest-auc:0.97113\n",
      "[63]\ttrain-auc:0.99303\ttest-auc:0.97235\n",
      "[64]\ttrain-auc:0.99427\ttest-auc:0.97160\n",
      "[65]\ttrain-auc:0.99423\ttest-auc:0.97099\n",
      "[66]\ttrain-auc:0.99430\ttest-auc:0.97259\n",
      "[67]\ttrain-auc:0.99480\ttest-auc:0.97355\n",
      "[68]\ttrain-auc:0.99511\ttest-auc:0.97358\n",
      "[69]\ttrain-auc:0.99515\ttest-auc:0.97465\n",
      "[70]\ttrain-auc:0.99531\ttest-auc:0.97558\n",
      "[71]\ttrain-auc:0.99553\ttest-auc:0.97542\n",
      "[72]\ttrain-auc:0.99565\ttest-auc:0.97689\n",
      "[73]\ttrain-auc:0.99577\ttest-auc:0.97661\n",
      "[74]\ttrain-auc:0.99575\ttest-auc:0.97675\n",
      "[75]\ttrain-auc:0.99586\ttest-auc:0.97735\n",
      "[76]\ttrain-auc:0.99629\ttest-auc:0.97792\n",
      "[77]\ttrain-auc:0.99672\ttest-auc:0.97764\n",
      "[78]\ttrain-auc:0.99683\ttest-auc:0.97716\n",
      "[79]\ttrain-auc:0.99709\ttest-auc:0.97825\n",
      "[80]\ttrain-auc:0.99722\ttest-auc:0.97825\n",
      "[81]\ttrain-auc:0.99737\ttest-auc:0.97850\n",
      "[82]\ttrain-auc:0.99740\ttest-auc:0.97847\n",
      "[83]\ttrain-auc:0.99745\ttest-auc:0.97844\n",
      "[84]\ttrain-auc:0.99752\ttest-auc:0.97827\n",
      "[85]\ttrain-auc:0.99759\ttest-auc:0.97848\n",
      "[86]\ttrain-auc:0.99764\ttest-auc:0.97843\n",
      "[87]\ttrain-auc:0.99764\ttest-auc:0.97883\n",
      "[88]\ttrain-auc:0.99763\ttest-auc:0.97870\n",
      "[89]\ttrain-auc:0.99781\ttest-auc:0.97862\n",
      "[90]\ttrain-auc:0.99792\ttest-auc:0.97847\n",
      "[91]\ttrain-auc:0.99796\ttest-auc:0.97878\n",
      "[92]\ttrain-auc:0.99801\ttest-auc:0.97852\n",
      "[93]\ttrain-auc:0.99803\ttest-auc:0.97835\n",
      "[94]\ttrain-auc:0.99805\ttest-auc:0.97853\n",
      "[95]\ttrain-auc:0.99823\ttest-auc:0.97770\n",
      "[96]\ttrain-auc:0.99830\ttest-auc:0.97783\n",
      "[97]\ttrain-auc:0.99831\ttest-auc:0.97740\n",
      "fit insult\n",
      "[20:16:50] WARNING: D:\\Build\\xgboost\\xgboost-1.5.1.git\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.73129\ttest-auc:0.73243\n",
      "[1]\ttrain-auc:0.78568\ttest-auc:0.79493\n",
      "[2]\ttrain-auc:0.80041\ttest-auc:0.80976\n",
      "[3]\ttrain-auc:0.80039\ttest-auc:0.80985\n",
      "[4]\ttrain-auc:0.80044\ttest-auc:0.80982\n",
      "[5]\ttrain-auc:0.80795\ttest-auc:0.81799\n",
      "[6]\ttrain-auc:0.84539\ttest-auc:0.84714\n",
      "[7]\ttrain-auc:0.85190\ttest-auc:0.85194\n",
      "[8]\ttrain-auc:0.85227\ttest-auc:0.85224\n",
      "[9]\ttrain-auc:0.86005\ttest-auc:0.86007\n",
      "[10]\ttrain-auc:0.86004\ttest-auc:0.86006\n",
      "[11]\ttrain-auc:0.86036\ttest-auc:0.86091\n",
      "[12]\ttrain-auc:0.89493\ttest-auc:0.88972\n",
      "[13]\ttrain-auc:0.89911\ttest-auc:0.89327\n",
      "[14]\ttrain-auc:0.90250\ttest-auc:0.89416\n",
      "[15]\ttrain-auc:0.91941\ttest-auc:0.91273\n",
      "[16]\ttrain-auc:0.91927\ttest-auc:0.91238\n",
      "[17]\ttrain-auc:0.92108\ttest-auc:0.91385\n",
      "[18]\ttrain-auc:0.92510\ttest-auc:0.91789\n",
      "[19]\ttrain-auc:0.92728\ttest-auc:0.92029\n",
      "[20]\ttrain-auc:0.92965\ttest-auc:0.92174\n",
      "[21]\ttrain-auc:0.93238\ttest-auc:0.92376\n",
      "[22]\ttrain-auc:0.93432\ttest-auc:0.92513\n",
      "[23]\ttrain-auc:0.93773\ttest-auc:0.92701\n",
      "[24]\ttrain-auc:0.94104\ttest-auc:0.93098\n",
      "[25]\ttrain-auc:0.94416\ttest-auc:0.93368\n",
      "[26]\ttrain-auc:0.94629\ttest-auc:0.93644\n",
      "[27]\ttrain-auc:0.94747\ttest-auc:0.93898\n",
      "[28]\ttrain-auc:0.94884\ttest-auc:0.93943\n",
      "[29]\ttrain-auc:0.95082\ttest-auc:0.94242\n",
      "[30]\ttrain-auc:0.95102\ttest-auc:0.94286\n",
      "[31]\ttrain-auc:0.95220\ttest-auc:0.94445\n",
      "[32]\ttrain-auc:0.95261\ttest-auc:0.94516\n",
      "[33]\ttrain-auc:0.95395\ttest-auc:0.94624\n",
      "[34]\ttrain-auc:0.95463\ttest-auc:0.94715\n",
      "[35]\ttrain-auc:0.95532\ttest-auc:0.94796\n",
      "[36]\ttrain-auc:0.95618\ttest-auc:0.94813\n",
      "[37]\ttrain-auc:0.95772\ttest-auc:0.94907\n",
      "[38]\ttrain-auc:0.95820\ttest-auc:0.94933\n",
      "[39]\ttrain-auc:0.95871\ttest-auc:0.94951\n",
      "[40]\ttrain-auc:0.95904\ttest-auc:0.94979\n",
      "[41]\ttrain-auc:0.95951\ttest-auc:0.95029\n",
      "[42]\ttrain-auc:0.96045\ttest-auc:0.95123\n",
      "[43]\ttrain-auc:0.96116\ttest-auc:0.95128\n",
      "[44]\ttrain-auc:0.96195\ttest-auc:0.95227\n",
      "[45]\ttrain-auc:0.96262\ttest-auc:0.95261\n",
      "[46]\ttrain-auc:0.96332\ttest-auc:0.95330\n",
      "[47]\ttrain-auc:0.96415\ttest-auc:0.95400\n",
      "[48]\ttrain-auc:0.96480\ttest-auc:0.95444\n",
      "[49]\ttrain-auc:0.96562\ttest-auc:0.95513\n",
      "[50]\ttrain-auc:0.96619\ttest-auc:0.95559\n",
      "[51]\ttrain-auc:0.96661\ttest-auc:0.95602\n",
      "[52]\ttrain-auc:0.96730\ttest-auc:0.95626\n",
      "[53]\ttrain-auc:0.96762\ttest-auc:0.95647\n",
      "[54]\ttrain-auc:0.96804\ttest-auc:0.95660\n",
      "[55]\ttrain-auc:0.96808\ttest-auc:0.95669\n",
      "[56]\ttrain-auc:0.96868\ttest-auc:0.95699\n",
      "[57]\ttrain-auc:0.96906\ttest-auc:0.95704\n",
      "[58]\ttrain-auc:0.96957\ttest-auc:0.95745\n",
      "[59]\ttrain-auc:0.96989\ttest-auc:0.95765\n",
      "[60]\ttrain-auc:0.97031\ttest-auc:0.95824\n",
      "[61]\ttrain-auc:0.97084\ttest-auc:0.95837\n",
      "[62]\ttrain-auc:0.97114\ttest-auc:0.95846\n",
      "[63]\ttrain-auc:0.97140\ttest-auc:0.95871\n",
      "[64]\ttrain-auc:0.97175\ttest-auc:0.95900\n",
      "[65]\ttrain-auc:0.97202\ttest-auc:0.95914\n",
      "[66]\ttrain-auc:0.97234\ttest-auc:0.95962\n",
      "[67]\ttrain-auc:0.97257\ttest-auc:0.96001\n",
      "[68]\ttrain-auc:0.97304\ttest-auc:0.96050\n",
      "[69]\ttrain-auc:0.97348\ttest-auc:0.96087\n",
      "[70]\ttrain-auc:0.97384\ttest-auc:0.96096\n",
      "[71]\ttrain-auc:0.97413\ttest-auc:0.96114\n",
      "[72]\ttrain-auc:0.97446\ttest-auc:0.96157\n",
      "[73]\ttrain-auc:0.97463\ttest-auc:0.96178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74]\ttrain-auc:0.97481\ttest-auc:0.96206\n",
      "[75]\ttrain-auc:0.97506\ttest-auc:0.96217\n",
      "[76]\ttrain-auc:0.97543\ttest-auc:0.96235\n",
      "[77]\ttrain-auc:0.97585\ttest-auc:0.96276\n",
      "[78]\ttrain-auc:0.97620\ttest-auc:0.96321\n",
      "[79]\ttrain-auc:0.97629\ttest-auc:0.96335\n",
      "[80]\ttrain-auc:0.97647\ttest-auc:0.96371\n",
      "[81]\ttrain-auc:0.97671\ttest-auc:0.96399\n",
      "[82]\ttrain-auc:0.97695\ttest-auc:0.96421\n",
      "[83]\ttrain-auc:0.97714\ttest-auc:0.96420\n",
      "[84]\ttrain-auc:0.97758\ttest-auc:0.96438\n",
      "[85]\ttrain-auc:0.97786\ttest-auc:0.96466\n",
      "[86]\ttrain-auc:0.97796\ttest-auc:0.96475\n",
      "[87]\ttrain-auc:0.97818\ttest-auc:0.96491\n",
      "[88]\ttrain-auc:0.97832\ttest-auc:0.96505\n",
      "[89]\ttrain-auc:0.97845\ttest-auc:0.96524\n",
      "[90]\ttrain-auc:0.97857\ttest-auc:0.96536\n",
      "[91]\ttrain-auc:0.97886\ttest-auc:0.96545\n",
      "[92]\ttrain-auc:0.97898\ttest-auc:0.96563\n",
      "[93]\ttrain-auc:0.97919\ttest-auc:0.96578\n",
      "[94]\ttrain-auc:0.97941\ttest-auc:0.96588\n",
      "[95]\ttrain-auc:0.97958\ttest-auc:0.96601\n",
      "[96]\ttrain-auc:0.97978\ttest-auc:0.96607\n",
      "[97]\ttrain-auc:0.97989\ttest-auc:0.96616\n",
      "[98]\ttrain-auc:0.98012\ttest-auc:0.96640\n",
      "[99]\ttrain-auc:0.98012\ttest-auc:0.96654\n",
      "fit identity_hate\n",
      "[20:18:00] WARNING: D:\\Build\\xgboost\\xgboost-1.5.1.git\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.75431\ttest-auc:0.72151\n",
      "[1]\ttrain-auc:0.81621\ttest-auc:0.77984\n",
      "[2]\ttrain-auc:0.82166\ttest-auc:0.78132\n",
      "[3]\ttrain-auc:0.82649\ttest-auc:0.78495\n",
      "[4]\ttrain-auc:0.82831\ttest-auc:0.78494\n",
      "[5]\ttrain-auc:0.82918\ttest-auc:0.78517\n",
      "[6]\ttrain-auc:0.83060\ttest-auc:0.78865\n",
      "[7]\ttrain-auc:0.83061\ttest-auc:0.78874\n",
      "[8]\ttrain-auc:0.85036\ttest-auc:0.79445\n",
      "[9]\ttrain-auc:0.85052\ttest-auc:0.79459\n",
      "[10]\ttrain-auc:0.85446\ttest-auc:0.79829\n",
      "[11]\ttrain-auc:0.85450\ttest-auc:0.79829\n",
      "[12]\ttrain-auc:0.86530\ttest-auc:0.80807\n",
      "[13]\ttrain-auc:0.86612\ttest-auc:0.80990\n",
      "[14]\ttrain-auc:0.87253\ttest-auc:0.81358\n",
      "[15]\ttrain-auc:0.87598\ttest-auc:0.81534\n",
      "[16]\ttrain-auc:0.87590\ttest-auc:0.81537\n",
      "[17]\ttrain-auc:0.87591\ttest-auc:0.81543\n",
      "[18]\ttrain-auc:0.87584\ttest-auc:0.81532\n",
      "[19]\ttrain-auc:0.87584\ttest-auc:0.81535\n",
      "[20]\ttrain-auc:0.88516\ttest-auc:0.83306\n",
      "[21]\ttrain-auc:0.88735\ttest-auc:0.83683\n",
      "[22]\ttrain-auc:0.88748\ttest-auc:0.83701\n",
      "[23]\ttrain-auc:0.89368\ttest-auc:0.84197\n",
      "[24]\ttrain-auc:0.89371\ttest-auc:0.84187\n",
      "[25]\ttrain-auc:0.89380\ttest-auc:0.84564\n",
      "[26]\ttrain-auc:0.89481\ttest-auc:0.84736\n",
      "[27]\ttrain-auc:0.90610\ttest-auc:0.85472\n",
      "[28]\ttrain-auc:0.90754\ttest-auc:0.85466\n",
      "[29]\ttrain-auc:0.91251\ttest-auc:0.85790\n",
      "[30]\ttrain-auc:0.91439\ttest-auc:0.85789\n",
      "[31]\ttrain-auc:0.91497\ttest-auc:0.85812\n",
      "[32]\ttrain-auc:0.91540\ttest-auc:0.85769\n",
      "[33]\ttrain-auc:0.91715\ttest-auc:0.85784\n",
      "[34]\ttrain-auc:0.92389\ttest-auc:0.86435\n",
      "[35]\ttrain-auc:0.92505\ttest-auc:0.86579\n",
      "[36]\ttrain-auc:0.93461\ttest-auc:0.87218\n",
      "[37]\ttrain-auc:0.93761\ttest-auc:0.87623\n",
      "[38]\ttrain-auc:0.93989\ttest-auc:0.87759\n",
      "[39]\ttrain-auc:0.94038\ttest-auc:0.87754\n",
      "[40]\ttrain-auc:0.94964\ttest-auc:0.90702\n",
      "[41]\ttrain-auc:0.95085\ttest-auc:0.90806\n",
      "[42]\ttrain-auc:0.95219\ttest-auc:0.90840\n",
      "[43]\ttrain-auc:0.95371\ttest-auc:0.90987\n",
      "[44]\ttrain-auc:0.95377\ttest-auc:0.91080\n",
      "[45]\ttrain-auc:0.95746\ttest-auc:0.91572\n",
      "[46]\ttrain-auc:0.96043\ttest-auc:0.91828\n",
      "[47]\ttrain-auc:0.96223\ttest-auc:0.92152\n",
      "[48]\ttrain-auc:0.96586\ttest-auc:0.92434\n",
      "[49]\ttrain-auc:0.96750\ttest-auc:0.92838\n",
      "[50]\ttrain-auc:0.96914\ttest-auc:0.93250\n",
      "[51]\ttrain-auc:0.97079\ttest-auc:0.93314\n",
      "[52]\ttrain-auc:0.97154\ttest-auc:0.93693\n",
      "[53]\ttrain-auc:0.97415\ttest-auc:0.93711\n",
      "[54]\ttrain-auc:0.97523\ttest-auc:0.93949\n",
      "[55]\ttrain-auc:0.97631\ttest-auc:0.94199\n",
      "[56]\ttrain-auc:0.97752\ttest-auc:0.94413\n",
      "[57]\ttrain-auc:0.97780\ttest-auc:0.94424\n",
      "[58]\ttrain-auc:0.97809\ttest-auc:0.94389\n",
      "[59]\ttrain-auc:0.97889\ttest-auc:0.94413\n",
      "[60]\ttrain-auc:0.98015\ttest-auc:0.94533\n",
      "[61]\ttrain-auc:0.98028\ttest-auc:0.94631\n",
      "[62]\ttrain-auc:0.98095\ttest-auc:0.94700\n",
      "[63]\ttrain-auc:0.98142\ttest-auc:0.94783\n",
      "[64]\ttrain-auc:0.98178\ttest-auc:0.94784\n",
      "[65]\ttrain-auc:0.98200\ttest-auc:0.94863\n",
      "[66]\ttrain-auc:0.98236\ttest-auc:0.94845\n",
      "[67]\ttrain-auc:0.98289\ttest-auc:0.95022\n",
      "[68]\ttrain-auc:0.98325\ttest-auc:0.95153\n",
      "[69]\ttrain-auc:0.98343\ttest-auc:0.95118\n",
      "[70]\ttrain-auc:0.98344\ttest-auc:0.95151\n",
      "[71]\ttrain-auc:0.98353\ttest-auc:0.95223\n",
      "[72]\ttrain-auc:0.98358\ttest-auc:0.95241\n",
      "[73]\ttrain-auc:0.98377\ttest-auc:0.95254\n",
      "[74]\ttrain-auc:0.98392\ttest-auc:0.95271\n",
      "[75]\ttrain-auc:0.98403\ttest-auc:0.95311\n",
      "[76]\ttrain-auc:0.98404\ttest-auc:0.95271\n",
      "[77]\ttrain-auc:0.98445\ttest-auc:0.95284\n",
      "[78]\ttrain-auc:0.98495\ttest-auc:0.95306\n",
      "[79]\ttrain-auc:0.98498\ttest-auc:0.95365\n",
      "[80]\ttrain-auc:0.98508\ttest-auc:0.95386\n",
      "[81]\ttrain-auc:0.98537\ttest-auc:0.95413\n",
      "[82]\ttrain-auc:0.98555\ttest-auc:0.95439\n",
      "[83]\ttrain-auc:0.98570\ttest-auc:0.95440\n",
      "[84]\ttrain-auc:0.98620\ttest-auc:0.95499\n",
      "[85]\ttrain-auc:0.98654\ttest-auc:0.95482\n",
      "[86]\ttrain-auc:0.98682\ttest-auc:0.95475\n",
      "[87]\ttrain-auc:0.98685\ttest-auc:0.95473\n",
      "[88]\ttrain-auc:0.98696\ttest-auc:0.95487\n",
      "[89]\ttrain-auc:0.98705\ttest-auc:0.95488\n",
      "[90]\ttrain-auc:0.98726\ttest-auc:0.95469\n",
      "[91]\ttrain-auc:0.98735\ttest-auc:0.95474\n",
      "[92]\ttrain-auc:0.98748\ttest-auc:0.95468\n",
      "[93]\ttrain-auc:0.98759\ttest-auc:0.95468\n"
     ]
    }
   ],
   "source": [
    "##这个也不好跑\n",
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "preds = np.zeros((test.shape[0], len(col)))\n",
    "\n",
    "for i, j in enumerate(col):\n",
    "    print('fit '+j)\n",
    "    model = run(comments_train, train_y[j], comments_val,val_y[j])\n",
    "    preds[:,i] = model.predict(xgb.DMatrix(comments_test), ntree_limit = model.best_ntree_limit)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##慢慢慢\n",
    "labels=pd.read_csv('bili_test_label.csv')\n",
    "labels=np.array(labels.iloc[:,1:])\n",
    "sum_labels=np.sum(labels,axis=1)\n",
    "idx=sum_labels>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 6), (100, 6))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_consider=preds[idx]\n",
    "labels_consider= labels[idx]\n",
    "preds_consider.shape,labels_consider.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058796</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.024539</td>\n",
       "      <td>0.005419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.742393</td>\n",
       "      <td>0.035874</td>\n",
       "      <td>0.940924</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.309874</td>\n",
       "      <td>0.006232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121828</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.035876</td>\n",
       "      <td>0.006386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059197</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.016351</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>0.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103977</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.031953</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.035427</td>\n",
       "      <td>0.006543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.055072</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.012714</td>\n",
       "      <td>0.003028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.011977</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.061814</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.022250</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.004960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.149896</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.028619</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>0.005681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "0   0.058796  0.004888  0.021741  0.000921  0.024539  0.005419\n",
       "1   0.742393  0.035874  0.940924  0.000454  0.309874  0.006232\n",
       "2   0.121828  0.007203  0.037679  0.001133  0.035876  0.006386\n",
       "3   0.059197  0.001628  0.016351  0.000846  0.013170  0.003497\n",
       "4   0.103977  0.006066  0.031953  0.001133  0.035427  0.006543\n",
       "..       ...       ...       ...       ...       ...       ...\n",
       "95  0.055072  0.001483  0.011606  0.000712  0.012714  0.003028\n",
       "96  0.028111  0.001634  0.010181  0.000774  0.011977  0.002618\n",
       "97  0.061814  0.004361  0.022250  0.000921  0.022836  0.004960\n",
       "98  0.026953  0.000888  0.011009  0.000417  0.009987  0.002093\n",
       "99  0.149896  0.002675  0.028619  0.001337  0.019782  0.005681\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output=pd.DataFrame(preds_consider)\n",
    "preds_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.056815</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.020984</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.024091</td>\n",
       "      <td>0.005074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.059738</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.025636</td>\n",
       "      <td>0.005367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.103977</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.031953</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.035427</td>\n",
       "      <td>0.006543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.086181</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.028202</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.032829</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.012792</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.003595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.055072</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.012714</td>\n",
       "      <td>0.003028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.011977</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.061814</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.022250</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.004960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.026953</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.149896</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.028619</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>0.005681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "90  0.056815  0.002836  0.020984  0.001009  0.024091  0.005074\n",
       "91  0.059738  0.003667  0.024451  0.000888  0.025636  0.005367\n",
       "92  0.103977  0.006066  0.031953  0.001133  0.035427  0.006543\n",
       "93  0.086181  0.002883  0.028202  0.001251  0.033409  0.006100\n",
       "94  0.032829  0.001784  0.012792  0.000670  0.012361  0.003595\n",
       "95  0.055072  0.001483  0.011606  0.000712  0.012714  0.003028\n",
       "96  0.028111  0.001634  0.010181  0.000774  0.011977  0.002618\n",
       "97  0.061814  0.004361  0.022250  0.000921  0.022836  0.004960\n",
       "98  0.026953  0.000888  0.011009  0.000417  0.009987  0.002093\n",
       "99  0.149896  0.002675  0.028619  0.001337  0.019782  0.005681"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 6), (100, 6))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_consider=preds[idx]\n",
    "labels_consider= labels[idx]\n",
    "preds_consider.shape,labels_consider.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
