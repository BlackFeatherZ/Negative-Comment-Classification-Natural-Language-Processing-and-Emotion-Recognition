{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train['comment_text'],train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']], test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "symbols = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return symbols.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ml_xi\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transform_function = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1).fit(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train = transform_function.transform(train_x)\n",
    "comments_val = transform_function.transform(val_x)\n",
    "comments_test = transform_function.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(train_x)\n",
    "val_x = pd.DataFrame(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = [train_x, val_x, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['total_length', 'capitals', 'caps_vs_length','num_exclamation_marks', 'num_question_marks', 'num_punctuation','num_symbols', 'num_words', 'num_unique_words', 'words_vs_unique','num_smilies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in combined:\n",
    "    data['total_length'] = data['comment_text'].apply(len)\n",
    "    data['capitals'] = data['comment_text'].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "    data['caps_vs_length'] = data.apply(lambda row: float(row['capitals'])/float(row['total_length']),\n",
    "                                axis=1)\n",
    "    data['num_exclamation_marks'] = data['comment_text'].apply(lambda x: x.count('!'))\n",
    "    data['num_question_marks'] = data['comment_text'].apply(lambda x: x.count('?'))\n",
    "    data['num_punctuation'] = data['comment_text'].apply(lambda x: sum(x.count(w) for w in '.,;:'))\n",
    "    data['num_symbols'] = data['comment_text'].apply(lambda x: sum(x.count(w) for w in '*&$%'))\n",
    "    data['num_words'] = data['comment_text'].apply(lambda x: len(x.split()))\n",
    "    data['num_unique_words'] = data['comment_text'].apply(lambda x: len(set(w for w in x.split())))\n",
    "    data['words_vs_unique'] = data['num_unique_words'] / data['num_words']\n",
    "    data['num_smilies'] = data['comment_text'].apply(lambda x: sum(x.count(w) for w in (':-)', ':)', ';-)', ';)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "train_x = scipy.sparse.csr_matrix(train_x[col].values)\n",
    "val_x = scipy.sparse.csr_matrix(val_x[col].values)\n",
    "test = scipy.sparse.csr_matrix(test[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train = scipy.sparse.hstack([train_x.tocsr(),comments_train.tocsr()])\n",
    "comments_val = scipy.sparse.hstack([val_x,comments_val])\n",
    "comments_test = scipy.sparse.hstack([test,comments_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost(train_X, train_y, test_X, test_y=None, feature_names=None):\n",
    "    dic = {}\n",
    "    #dic['objective'] = 'binary:logistic'\n",
    "    #dic['eta'] = 0.1\n",
    "    #dic['max_depth'] = 6\n",
    "    #dic['silent'] = 1\n",
    "    #dic['eval_metric'] = 'auc'\n",
    "    #dic['min_child_weight'] = 1\n",
    "    #dic['subsample'] = 0.7\n",
    "    #dic['colsample_bytree'] = 0.7\n",
    "    num = 100\n",
    "    list_dic = list(dic.items())\n",
    "\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "\n",
    "    model = xgb.train(list_dic, xgtrain, num, [ (xgtrain,'train'), (xgtest, 'test') ], early_stopping_rounds=10)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit toxic\n",
      "[0]\ttrain-rmse:0.38988\ttest-rmse:0.39070\n",
      "[1]\ttrain-rmse:0.32039\ttest-rmse:0.32197\n",
      "[2]\ttrain-rmse:0.27913\ttest-rmse:0.28141\n",
      "[3]\ttrain-rmse:0.25346\ttest-rmse:0.25658\n",
      "[4]\ttrain-rmse:0.23821\ttest-rmse:0.24219\n",
      "[5]\ttrain-rmse:0.22921\ttest-rmse:0.23340\n",
      "[6]\ttrain-rmse:0.22276\ttest-rmse:0.22791\n",
      "[7]\ttrain-rmse:0.21823\ttest-rmse:0.22421\n",
      "[8]\ttrain-rmse:0.21471\ttest-rmse:0.22140\n",
      "[9]\ttrain-rmse:0.21133\ttest-rmse:0.21877\n",
      "[10]\ttrain-rmse:0.20917\ttest-rmse:0.21638\n",
      "[11]\ttrain-rmse:0.20718\ttest-rmse:0.21502\n",
      "[12]\ttrain-rmse:0.20521\ttest-rmse:0.21340\n",
      "[13]\ttrain-rmse:0.20342\ttest-rmse:0.21194\n",
      "[14]\ttrain-rmse:0.20175\ttest-rmse:0.21074\n",
      "[15]\ttrain-rmse:0.20012\ttest-rmse:0.20997\n",
      "[16]\ttrain-rmse:0.19867\ttest-rmse:0.20914\n",
      "[17]\ttrain-rmse:0.19697\ttest-rmse:0.20814\n",
      "[18]\ttrain-rmse:0.19565\ttest-rmse:0.20756\n",
      "[19]\ttrain-rmse:0.19455\ttest-rmse:0.20678\n",
      "[20]\ttrain-rmse:0.19346\ttest-rmse:0.20617\n",
      "[21]\ttrain-rmse:0.19190\ttest-rmse:0.20524\n",
      "[22]\ttrain-rmse:0.19099\ttest-rmse:0.20451\n",
      "[23]\ttrain-rmse:0.19012\ttest-rmse:0.20395\n",
      "[24]\ttrain-rmse:0.18931\ttest-rmse:0.20331\n",
      "[25]\ttrain-rmse:0.18859\ttest-rmse:0.20289\n",
      "[26]\ttrain-rmse:0.18784\ttest-rmse:0.20238\n",
      "[27]\ttrain-rmse:0.18716\ttest-rmse:0.20210\n",
      "[28]\ttrain-rmse:0.18640\ttest-rmse:0.20188\n",
      "[29]\ttrain-rmse:0.18565\ttest-rmse:0.20146\n",
      "[30]\ttrain-rmse:0.18497\ttest-rmse:0.20139\n",
      "[31]\ttrain-rmse:0.18421\ttest-rmse:0.20094\n",
      "[32]\ttrain-rmse:0.18361\ttest-rmse:0.20084\n",
      "[33]\ttrain-rmse:0.18296\ttest-rmse:0.20059\n",
      "[34]\ttrain-rmse:0.18209\ttest-rmse:0.20011\n",
      "[35]\ttrain-rmse:0.18138\ttest-rmse:0.19987\n",
      "[36]\ttrain-rmse:0.18075\ttest-rmse:0.19969\n",
      "[37]\ttrain-rmse:0.17993\ttest-rmse:0.19950\n",
      "[38]\ttrain-rmse:0.17942\ttest-rmse:0.19926\n",
      "[39]\ttrain-rmse:0.17877\ttest-rmse:0.19904\n",
      "[40]\ttrain-rmse:0.17829\ttest-rmse:0.19889\n",
      "[41]\ttrain-rmse:0.17782\ttest-rmse:0.19881\n",
      "[42]\ttrain-rmse:0.17730\ttest-rmse:0.19870\n",
      "[43]\ttrain-rmse:0.17677\ttest-rmse:0.19848\n",
      "[44]\ttrain-rmse:0.17620\ttest-rmse:0.19808\n",
      "[45]\ttrain-rmse:0.17581\ttest-rmse:0.19786\n",
      "[46]\ttrain-rmse:0.17535\ttest-rmse:0.19766\n",
      "[47]\ttrain-rmse:0.17494\ttest-rmse:0.19755\n",
      "[48]\ttrain-rmse:0.17453\ttest-rmse:0.19743\n",
      "[49]\ttrain-rmse:0.17397\ttest-rmse:0.19723\n",
      "[50]\ttrain-rmse:0.17344\ttest-rmse:0.19700\n",
      "[51]\ttrain-rmse:0.17297\ttest-rmse:0.19695\n",
      "[52]\ttrain-rmse:0.17260\ttest-rmse:0.19686\n",
      "[53]\ttrain-rmse:0.17203\ttest-rmse:0.19648\n",
      "[54]\ttrain-rmse:0.17167\ttest-rmse:0.19632\n",
      "[55]\ttrain-rmse:0.17123\ttest-rmse:0.19618\n",
      "[56]\ttrain-rmse:0.17092\ttest-rmse:0.19614\n",
      "[57]\ttrain-rmse:0.17047\ttest-rmse:0.19602\n",
      "[58]\ttrain-rmse:0.17017\ttest-rmse:0.19576\n",
      "[59]\ttrain-rmse:0.16972\ttest-rmse:0.19570\n",
      "[60]\ttrain-rmse:0.16918\ttest-rmse:0.19552\n",
      "[61]\ttrain-rmse:0.16894\ttest-rmse:0.19546\n",
      "[62]\ttrain-rmse:0.16860\ttest-rmse:0.19535\n",
      "[63]\ttrain-rmse:0.16835\ttest-rmse:0.19526\n",
      "[64]\ttrain-rmse:0.16806\ttest-rmse:0.19517\n",
      "[65]\ttrain-rmse:0.16772\ttest-rmse:0.19507\n",
      "[66]\ttrain-rmse:0.16744\ttest-rmse:0.19495\n",
      "[67]\ttrain-rmse:0.16716\ttest-rmse:0.19497\n",
      "[68]\ttrain-rmse:0.16671\ttest-rmse:0.19492\n",
      "[69]\ttrain-rmse:0.16639\ttest-rmse:0.19491\n",
      "[70]\ttrain-rmse:0.16619\ttest-rmse:0.19486\n",
      "[71]\ttrain-rmse:0.16589\ttest-rmse:0.19477\n",
      "[72]\ttrain-rmse:0.16557\ttest-rmse:0.19466\n",
      "[73]\ttrain-rmse:0.16527\ttest-rmse:0.19457\n",
      "[74]\ttrain-rmse:0.16501\ttest-rmse:0.19448\n",
      "[75]\ttrain-rmse:0.16460\ttest-rmse:0.19435\n",
      "[76]\ttrain-rmse:0.16440\ttest-rmse:0.19429\n",
      "[77]\ttrain-rmse:0.16415\ttest-rmse:0.19417\n",
      "[78]\ttrain-rmse:0.16383\ttest-rmse:0.19408\n",
      "[79]\ttrain-rmse:0.16348\ttest-rmse:0.19417\n",
      "[80]\ttrain-rmse:0.16326\ttest-rmse:0.19409\n",
      "[81]\ttrain-rmse:0.16299\ttest-rmse:0.19404\n",
      "[82]\ttrain-rmse:0.16275\ttest-rmse:0.19400\n",
      "[83]\ttrain-rmse:0.16255\ttest-rmse:0.19404\n",
      "[84]\ttrain-rmse:0.16222\ttest-rmse:0.19397\n",
      "[85]\ttrain-rmse:0.16205\ttest-rmse:0.19393\n",
      "[86]\ttrain-rmse:0.16180\ttest-rmse:0.19383\n",
      "[87]\ttrain-rmse:0.16153\ttest-rmse:0.19378\n",
      "[88]\ttrain-rmse:0.16134\ttest-rmse:0.19375\n",
      "[89]\ttrain-rmse:0.16107\ttest-rmse:0.19368\n",
      "[90]\ttrain-rmse:0.16090\ttest-rmse:0.19361\n",
      "[91]\ttrain-rmse:0.16070\ttest-rmse:0.19357\n",
      "[92]\ttrain-rmse:0.16044\ttest-rmse:0.19345\n",
      "[93]\ttrain-rmse:0.16020\ttest-rmse:0.19341\n",
      "[94]\ttrain-rmse:0.16000\ttest-rmse:0.19339\n",
      "[95]\ttrain-rmse:0.15978\ttest-rmse:0.19335\n",
      "[96]\ttrain-rmse:0.15948\ttest-rmse:0.19329\n",
      "[97]\ttrain-rmse:0.15927\ttest-rmse:0.19326\n",
      "[98]\ttrain-rmse:0.15906\ttest-rmse:0.19321\n",
      "[99]\ttrain-rmse:0.15887\ttest-rmse:0.19321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ml_xi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit severe_toxic\n",
      "[0]\ttrain-rmse:0.35502\ttest-rmse:0.35564\n",
      "[1]\ttrain-rmse:0.25520\ttest-rmse:0.25672\n",
      "[2]\ttrain-rmse:0.18739\ttest-rmse:0.19029\n",
      "[3]\ttrain-rmse:0.14234\ttest-rmse:0.14709\n",
      "[4]\ttrain-rmse:0.11349\ttest-rmse:0.12024\n",
      "[5]\ttrain-rmse:0.09575\ttest-rmse:0.10469\n",
      "[6]\ttrain-rmse:0.08531\ttest-rmse:0.09601\n",
      "[7]\ttrain-rmse:0.07944\ttest-rmse:0.09146\n",
      "[8]\ttrain-rmse:0.07578\ttest-rmse:0.08926\n",
      "[9]\ttrain-rmse:0.07351\ttest-rmse:0.08801\n",
      "[10]\ttrain-rmse:0.07222\ttest-rmse:0.08732\n",
      "[11]\ttrain-rmse:0.07138\ttest-rmse:0.08697\n",
      "[12]\ttrain-rmse:0.07082\ttest-rmse:0.08685\n",
      "[13]\ttrain-rmse:0.07034\ttest-rmse:0.08679\n",
      "[14]\ttrain-rmse:0.06978\ttest-rmse:0.08672\n",
      "[15]\ttrain-rmse:0.06899\ttest-rmse:0.08635\n",
      "[16]\ttrain-rmse:0.06861\ttest-rmse:0.08633\n",
      "[17]\ttrain-rmse:0.06837\ttest-rmse:0.08633\n",
      "[18]\ttrain-rmse:0.06809\ttest-rmse:0.08631\n",
      "[19]\ttrain-rmse:0.06769\ttest-rmse:0.08635\n",
      "[20]\ttrain-rmse:0.06735\ttest-rmse:0.08641\n",
      "[21]\ttrain-rmse:0.06714\ttest-rmse:0.08639\n",
      "[22]\ttrain-rmse:0.06691\ttest-rmse:0.08639\n",
      "[23]\ttrain-rmse:0.06673\ttest-rmse:0.08635\n",
      "[24]\ttrain-rmse:0.06644\ttest-rmse:0.08636\n",
      "[25]\ttrain-rmse:0.06621\ttest-rmse:0.08643\n",
      "[26]\ttrain-rmse:0.06599\ttest-rmse:0.08627\n",
      "[27]\ttrain-rmse:0.06583\ttest-rmse:0.08630\n",
      "[28]\ttrain-rmse:0.06561\ttest-rmse:0.08630\n",
      "[29]\ttrain-rmse:0.06537\ttest-rmse:0.08629\n",
      "[30]\ttrain-rmse:0.06502\ttest-rmse:0.08628\n",
      "[31]\ttrain-rmse:0.06482\ttest-rmse:0.08635\n",
      "[32]\ttrain-rmse:0.06455\ttest-rmse:0.08638\n",
      "[33]\ttrain-rmse:0.06436\ttest-rmse:0.08639\n",
      "[34]\ttrain-rmse:0.06406\ttest-rmse:0.08640\n",
      "[35]\ttrain-rmse:0.06388\ttest-rmse:0.08642\n",
      "[36]\ttrain-rmse:0.06365\ttest-rmse:0.08639\n",
      "fit obscene\n",
      "[0]\ttrain-rmse:0.36686\ttest-rmse:0.36727\n",
      "[1]\ttrain-rmse:0.27859\ttest-rmse:0.27988\n",
      "[2]\ttrain-rmse:0.22133\ttest-rmse:0.22329\n",
      "[3]\ttrain-rmse:0.18634\ttest-rmse:0.18960\n",
      "[4]\ttrain-rmse:0.16477\ttest-rmse:0.16949\n",
      "[5]\ttrain-rmse:0.15189\ttest-rmse:0.15733\n",
      "[6]\ttrain-rmse:0.14380\ttest-rmse:0.15035\n",
      "[7]\ttrain-rmse:0.13826\ttest-rmse:0.14606\n",
      "[8]\ttrain-rmse:0.13450\ttest-rmse:0.14315\n",
      "[9]\ttrain-rmse:0.13181\ttest-rmse:0.14089\n",
      "[10]\ttrain-rmse:0.12981\ttest-rmse:0.13949\n",
      "[11]\ttrain-rmse:0.12828\ttest-rmse:0.13853\n",
      "[12]\ttrain-rmse:0.12684\ttest-rmse:0.13765\n",
      "[13]\ttrain-rmse:0.12531\ttest-rmse:0.13711\n",
      "[14]\ttrain-rmse:0.12417\ttest-rmse:0.13654\n",
      "[15]\ttrain-rmse:0.12280\ttest-rmse:0.13564\n",
      "[16]\ttrain-rmse:0.12180\ttest-rmse:0.13507\n",
      "[17]\ttrain-rmse:0.12084\ttest-rmse:0.13457\n",
      "[18]\ttrain-rmse:0.12002\ttest-rmse:0.13408\n",
      "[19]\ttrain-rmse:0.11886\ttest-rmse:0.13360\n",
      "[20]\ttrain-rmse:0.11810\ttest-rmse:0.13327\n",
      "[21]\ttrain-rmse:0.11744\ttest-rmse:0.13310\n",
      "[22]\ttrain-rmse:0.11651\ttest-rmse:0.13278\n",
      "[23]\ttrain-rmse:0.11572\ttest-rmse:0.13248\n",
      "[24]\ttrain-rmse:0.11508\ttest-rmse:0.13231\n",
      "[25]\ttrain-rmse:0.11444\ttest-rmse:0.13209\n",
      "[26]\ttrain-rmse:0.11387\ttest-rmse:0.13186\n",
      "[27]\ttrain-rmse:0.11330\ttest-rmse:0.13161\n",
      "[28]\ttrain-rmse:0.11283\ttest-rmse:0.13131\n",
      "[29]\ttrain-rmse:0.11212\ttest-rmse:0.13112\n",
      "[30]\ttrain-rmse:0.11153\ttest-rmse:0.13093\n",
      "[31]\ttrain-rmse:0.11109\ttest-rmse:0.13072\n",
      "[32]\ttrain-rmse:0.11069\ttest-rmse:0.13060\n",
      "[33]\ttrain-rmse:0.11021\ttest-rmse:0.13060\n",
      "[34]\ttrain-rmse:0.10970\ttest-rmse:0.13045\n",
      "[35]\ttrain-rmse:0.10914\ttest-rmse:0.13015\n",
      "[36]\ttrain-rmse:0.10877\ttest-rmse:0.13007\n",
      "[37]\ttrain-rmse:0.10844\ttest-rmse:0.13001\n",
      "[38]\ttrain-rmse:0.10807\ttest-rmse:0.12991\n",
      "[39]\ttrain-rmse:0.10766\ttest-rmse:0.12974\n",
      "[40]\ttrain-rmse:0.10735\ttest-rmse:0.12969\n",
      "[41]\ttrain-rmse:0.10670\ttest-rmse:0.12939\n",
      "[42]\ttrain-rmse:0.10634\ttest-rmse:0.12938\n",
      "[43]\ttrain-rmse:0.10606\ttest-rmse:0.12918\n",
      "[44]\ttrain-rmse:0.10577\ttest-rmse:0.12911\n",
      "[45]\ttrain-rmse:0.10547\ttest-rmse:0.12912\n",
      "[46]\ttrain-rmse:0.10513\ttest-rmse:0.12892\n",
      "[47]\ttrain-rmse:0.10491\ttest-rmse:0.12887\n",
      "[48]\ttrain-rmse:0.10462\ttest-rmse:0.12865\n",
      "[49]\ttrain-rmse:0.10430\ttest-rmse:0.12861\n",
      "[50]\ttrain-rmse:0.10408\ttest-rmse:0.12849\n",
      "[51]\ttrain-rmse:0.10385\ttest-rmse:0.12844\n",
      "[52]\ttrain-rmse:0.10360\ttest-rmse:0.12840\n",
      "[53]\ttrain-rmse:0.10319\ttest-rmse:0.12835\n",
      "[54]\ttrain-rmse:0.10297\ttest-rmse:0.12836\n",
      "[55]\ttrain-rmse:0.10281\ttest-rmse:0.12833\n",
      "[56]\ttrain-rmse:0.10261\ttest-rmse:0.12837\n",
      "[57]\ttrain-rmse:0.10238\ttest-rmse:0.12834\n",
      "[58]\ttrain-rmse:0.10218\ttest-rmse:0.12840\n",
      "[59]\ttrain-rmse:0.10196\ttest-rmse:0.12837\n",
      "[60]\ttrain-rmse:0.10171\ttest-rmse:0.12831\n",
      "[61]\ttrain-rmse:0.10145\ttest-rmse:0.12829\n",
      "[62]\ttrain-rmse:0.10127\ttest-rmse:0.12830\n",
      "[63]\ttrain-rmse:0.10111\ttest-rmse:0.12829\n",
      "[64]\ttrain-rmse:0.10092\ttest-rmse:0.12825\n",
      "[65]\ttrain-rmse:0.10056\ttest-rmse:0.12826\n",
      "[66]\ttrain-rmse:0.10025\ttest-rmse:0.12828\n",
      "[67]\ttrain-rmse:0.10007\ttest-rmse:0.12827\n",
      "[68]\ttrain-rmse:0.09975\ttest-rmse:0.12825\n",
      "[69]\ttrain-rmse:0.09954\ttest-rmse:0.12822\n",
      "[70]\ttrain-rmse:0.09904\ttest-rmse:0.12809\n",
      "[71]\ttrain-rmse:0.09888\ttest-rmse:0.12802\n",
      "[72]\ttrain-rmse:0.09875\ttest-rmse:0.12803\n",
      "[73]\ttrain-rmse:0.09847\ttest-rmse:0.12801\n",
      "[74]\ttrain-rmse:0.09828\ttest-rmse:0.12790\n",
      "[75]\ttrain-rmse:0.09811\ttest-rmse:0.12791\n",
      "[76]\ttrain-rmse:0.09797\ttest-rmse:0.12790\n",
      "[77]\ttrain-rmse:0.09776\ttest-rmse:0.12785\n",
      "[78]\ttrain-rmse:0.09763\ttest-rmse:0.12785\n",
      "[79]\ttrain-rmse:0.09751\ttest-rmse:0.12792\n",
      "[80]\ttrain-rmse:0.09737\ttest-rmse:0.12799\n",
      "[81]\ttrain-rmse:0.09718\ttest-rmse:0.12796\n",
      "[82]\ttrain-rmse:0.09705\ttest-rmse:0.12801\n",
      "[83]\ttrain-rmse:0.09692\ttest-rmse:0.12800\n",
      "[84]\ttrain-rmse:0.09678\ttest-rmse:0.12795\n",
      "[85]\ttrain-rmse:0.09662\ttest-rmse:0.12791\n",
      "[86]\ttrain-rmse:0.09646\ttest-rmse:0.12791\n",
      "[87]\ttrain-rmse:0.09632\ttest-rmse:0.12789\n",
      "fit threat\n",
      "[0]\ttrain-rmse:0.35155\ttest-rmse:0.35170\n",
      "[1]\ttrain-rmse:0.24815\ttest-rmse:0.24850\n",
      "[2]\ttrain-rmse:0.17634\ttest-rmse:0.17700\n",
      "[3]\ttrain-rmse:0.12711\ttest-rmse:0.12815\n",
      "[4]\ttrain-rmse:0.09369\ttest-rmse:0.09531\n",
      "[5]\ttrain-rmse:0.07149\ttest-rmse:0.07420\n",
      "[6]\ttrain-rmse:0.05752\ttest-rmse:0.06138\n",
      "[7]\ttrain-rmse:0.04908\ttest-rmse:0.05374\n",
      "[8]\ttrain-rmse:0.04411\ttest-rmse:0.04963\n",
      "[9]\ttrain-rmse:0.04098\ttest-rmse:0.04722\n",
      "[10]\ttrain-rmse:0.03924\ttest-rmse:0.04627\n",
      "[11]\ttrain-rmse:0.03819\ttest-rmse:0.04574\n",
      "[12]\ttrain-rmse:0.03705\ttest-rmse:0.04527\n",
      "[13]\ttrain-rmse:0.03655\ttest-rmse:0.04520\n",
      "[14]\ttrain-rmse:0.03607\ttest-rmse:0.04514\n",
      "[15]\ttrain-rmse:0.03558\ttest-rmse:0.04497\n",
      "[16]\ttrain-rmse:0.03493\ttest-rmse:0.04465\n",
      "[17]\ttrain-rmse:0.03447\ttest-rmse:0.04457\n",
      "[18]\ttrain-rmse:0.03414\ttest-rmse:0.04474\n",
      "[19]\ttrain-rmse:0.03380\ttest-rmse:0.04489\n",
      "[20]\ttrain-rmse:0.03312\ttest-rmse:0.04489\n",
      "[21]\ttrain-rmse:0.03285\ttest-rmse:0.04488\n",
      "[22]\ttrain-rmse:0.03259\ttest-rmse:0.04495\n",
      "[23]\ttrain-rmse:0.03239\ttest-rmse:0.04495\n",
      "[24]\ttrain-rmse:0.03219\ttest-rmse:0.04497\n",
      "[25]\ttrain-rmse:0.03199\ttest-rmse:0.04497\n",
      "[26]\ttrain-rmse:0.03178\ttest-rmse:0.04498\n",
      "fit insult\n",
      "[0]\ttrain-rmse:0.37139\ttest-rmse:0.37140\n",
      "[1]\ttrain-rmse:0.28677\ttest-rmse:0.28742\n",
      "[2]\ttrain-rmse:0.23365\ttest-rmse:0.23425\n",
      "[3]\ttrain-rmse:0.20094\ttest-rmse:0.20243\n",
      "[4]\ttrain-rmse:0.18124\ttest-rmse:0.18358\n",
      "[5]\ttrain-rmse:0.16926\ttest-rmse:0.17245\n",
      "[6]\ttrain-rmse:0.16200\ttest-rmse:0.16607\n",
      "[7]\ttrain-rmse:0.15727\ttest-rmse:0.16197\n",
      "[8]\ttrain-rmse:0.15393\ttest-rmse:0.15961\n",
      "[9]\ttrain-rmse:0.15142\ttest-rmse:0.15775\n",
      "[10]\ttrain-rmse:0.14910\ttest-rmse:0.15626\n",
      "[11]\ttrain-rmse:0.14752\ttest-rmse:0.15529\n",
      "[12]\ttrain-rmse:0.14606\ttest-rmse:0.15471\n",
      "[13]\ttrain-rmse:0.14472\ttest-rmse:0.15408\n",
      "[14]\ttrain-rmse:0.14358\ttest-rmse:0.15345\n",
      "[15]\ttrain-rmse:0.14250\ttest-rmse:0.15293\n",
      "[16]\ttrain-rmse:0.14144\ttest-rmse:0.15273\n",
      "[17]\ttrain-rmse:0.14047\ttest-rmse:0.15226\n",
      "[18]\ttrain-rmse:0.13959\ttest-rmse:0.15191\n",
      "[19]\ttrain-rmse:0.13869\ttest-rmse:0.15150\n",
      "[20]\ttrain-rmse:0.13791\ttest-rmse:0.15123\n",
      "[21]\ttrain-rmse:0.13707\ttest-rmse:0.15087\n",
      "[22]\ttrain-rmse:0.13634\ttest-rmse:0.15062\n",
      "[23]\ttrain-rmse:0.13569\ttest-rmse:0.15044\n",
      "[24]\ttrain-rmse:0.13512\ttest-rmse:0.15036\n",
      "[25]\ttrain-rmse:0.13443\ttest-rmse:0.15007\n",
      "[26]\ttrain-rmse:0.13385\ttest-rmse:0.14993\n",
      "[27]\ttrain-rmse:0.13324\ttest-rmse:0.14970\n",
      "[28]\ttrain-rmse:0.13259\ttest-rmse:0.14950\n",
      "[29]\ttrain-rmse:0.13198\ttest-rmse:0.14942\n",
      "[30]\ttrain-rmse:0.13151\ttest-rmse:0.14932\n",
      "[31]\ttrain-rmse:0.13093\ttest-rmse:0.14923\n",
      "[32]\ttrain-rmse:0.13039\ttest-rmse:0.14906\n",
      "[33]\ttrain-rmse:0.12995\ttest-rmse:0.14900\n",
      "[34]\ttrain-rmse:0.12946\ttest-rmse:0.14881\n",
      "[35]\ttrain-rmse:0.12908\ttest-rmse:0.14877\n",
      "[36]\ttrain-rmse:0.12854\ttest-rmse:0.14866\n",
      "[37]\ttrain-rmse:0.12812\ttest-rmse:0.14858\n",
      "[38]\ttrain-rmse:0.12765\ttest-rmse:0.14835\n",
      "[39]\ttrain-rmse:0.12714\ttest-rmse:0.14830\n",
      "[40]\ttrain-rmse:0.12680\ttest-rmse:0.14822\n",
      "[41]\ttrain-rmse:0.12653\ttest-rmse:0.14819\n",
      "[42]\ttrain-rmse:0.12627\ttest-rmse:0.14810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\ttrain-rmse:0.12599\ttest-rmse:0.14807\n",
      "[44]\ttrain-rmse:0.12565\ttest-rmse:0.14801\n",
      "[45]\ttrain-rmse:0.12525\ttest-rmse:0.14796\n",
      "[46]\ttrain-rmse:0.12497\ttest-rmse:0.14788\n",
      "[47]\ttrain-rmse:0.12461\ttest-rmse:0.14779\n",
      "[48]\ttrain-rmse:0.12424\ttest-rmse:0.14779\n",
      "[49]\ttrain-rmse:0.12381\ttest-rmse:0.14774\n",
      "[50]\ttrain-rmse:0.12350\ttest-rmse:0.14762\n",
      "[51]\ttrain-rmse:0.12322\ttest-rmse:0.14752\n",
      "[52]\ttrain-rmse:0.12298\ttest-rmse:0.14740\n",
      "[53]\ttrain-rmse:0.12272\ttest-rmse:0.14737\n",
      "[54]\ttrain-rmse:0.12239\ttest-rmse:0.14729\n",
      "[55]\ttrain-rmse:0.12211\ttest-rmse:0.14729\n",
      "[56]\ttrain-rmse:0.12183\ttest-rmse:0.14734\n",
      "[57]\ttrain-rmse:0.12163\ttest-rmse:0.14723\n",
      "[58]\ttrain-rmse:0.12134\ttest-rmse:0.14721\n",
      "[59]\ttrain-rmse:0.12110\ttest-rmse:0.14724\n",
      "[60]\ttrain-rmse:0.12082\ttest-rmse:0.14720\n",
      "[61]\ttrain-rmse:0.12061\ttest-rmse:0.14709\n",
      "[62]\ttrain-rmse:0.12025\ttest-rmse:0.14704\n",
      "[63]\ttrain-rmse:0.12008\ttest-rmse:0.14700\n",
      "[64]\ttrain-rmse:0.11988\ttest-rmse:0.14699\n",
      "[65]\ttrain-rmse:0.11971\ttest-rmse:0.14708\n",
      "[66]\ttrain-rmse:0.11949\ttest-rmse:0.14708\n",
      "[67]\ttrain-rmse:0.11934\ttest-rmse:0.14711\n",
      "[68]\ttrain-rmse:0.11916\ttest-rmse:0.14709\n",
      "[69]\ttrain-rmse:0.11896\ttest-rmse:0.14709\n",
      "[70]\ttrain-rmse:0.11878\ttest-rmse:0.14714\n",
      "[71]\ttrain-rmse:0.11858\ttest-rmse:0.14713\n",
      "[72]\ttrain-rmse:0.11840\ttest-rmse:0.14716\n",
      "[73]\ttrain-rmse:0.11821\ttest-rmse:0.14710\n",
      "fit identity_hate\n",
      "[0]\ttrain-rmse:0.35461\ttest-rmse:0.35496\n",
      "[1]\ttrain-rmse:0.25436\ttest-rmse:0.25524\n",
      "[2]\ttrain-rmse:0.18616\ttest-rmse:0.18786\n",
      "[3]\ttrain-rmse:0.14083\ttest-rmse:0.14364\n",
      "[4]\ttrain-rmse:0.11194\ttest-rmse:0.11591\n",
      "[5]\ttrain-rmse:0.09416\ttest-rmse:0.09935\n",
      "[6]\ttrain-rmse:0.08341\ttest-rmse:0.08989\n",
      "[7]\ttrain-rmse:0.07713\ttest-rmse:0.08480\n",
      "[8]\ttrain-rmse:0.07336\ttest-rmse:0.08208\n",
      "[9]\ttrain-rmse:0.07142\ttest-rmse:0.08077\n",
      "[10]\ttrain-rmse:0.06991\ttest-rmse:0.07999\n",
      "[11]\ttrain-rmse:0.06873\ttest-rmse:0.07936\n",
      "[12]\ttrain-rmse:0.06800\ttest-rmse:0.07916\n",
      "[13]\ttrain-rmse:0.06739\ttest-rmse:0.07905\n",
      "[14]\ttrain-rmse:0.06694\ttest-rmse:0.07902\n",
      "[15]\ttrain-rmse:0.06658\ttest-rmse:0.07896\n",
      "[16]\ttrain-rmse:0.06612\ttest-rmse:0.07891\n",
      "[17]\ttrain-rmse:0.06589\ttest-rmse:0.07893\n",
      "[18]\ttrain-rmse:0.06515\ttest-rmse:0.07878\n",
      "[19]\ttrain-rmse:0.06477\ttest-rmse:0.07874\n",
      "[20]\ttrain-rmse:0.06453\ttest-rmse:0.07878\n",
      "[21]\ttrain-rmse:0.06416\ttest-rmse:0.07866\n",
      "[22]\ttrain-rmse:0.06386\ttest-rmse:0.07867\n",
      "[23]\ttrain-rmse:0.06357\ttest-rmse:0.07862\n",
      "[24]\ttrain-rmse:0.06330\ttest-rmse:0.07852\n",
      "[25]\ttrain-rmse:0.06296\ttest-rmse:0.07853\n",
      "[26]\ttrain-rmse:0.06274\ttest-rmse:0.07849\n",
      "[27]\ttrain-rmse:0.06229\ttest-rmse:0.07853\n",
      "[28]\ttrain-rmse:0.06205\ttest-rmse:0.07848\n",
      "[29]\ttrain-rmse:0.06186\ttest-rmse:0.07851\n",
      "[30]\ttrain-rmse:0.06168\ttest-rmse:0.07857\n",
      "[31]\ttrain-rmse:0.06150\ttest-rmse:0.07861\n",
      "[32]\ttrain-rmse:0.06127\ttest-rmse:0.07859\n",
      "[33]\ttrain-rmse:0.06101\ttest-rmse:0.07854\n",
      "[34]\ttrain-rmse:0.06075\ttest-rmse:0.07856\n",
      "[35]\ttrain-rmse:0.06056\ttest-rmse:0.07858\n",
      "[36]\ttrain-rmse:0.06030\ttest-rmse:0.07860\n",
      "[37]\ttrain-rmse:0.05990\ttest-rmse:0.07842\n",
      "[38]\ttrain-rmse:0.05967\ttest-rmse:0.07850\n",
      "[39]\ttrain-rmse:0.05947\ttest-rmse:0.07842\n",
      "[40]\ttrain-rmse:0.05927\ttest-rmse:0.07842\n",
      "[41]\ttrain-rmse:0.05902\ttest-rmse:0.07845\n",
      "[42]\ttrain-rmse:0.05882\ttest-rmse:0.07843\n",
      "[43]\ttrain-rmse:0.05851\ttest-rmse:0.07841\n",
      "[44]\ttrain-rmse:0.05837\ttest-rmse:0.07843\n",
      "[45]\ttrain-rmse:0.05819\ttest-rmse:0.07841\n",
      "[46]\ttrain-rmse:0.05799\ttest-rmse:0.07839\n",
      "[47]\ttrain-rmse:0.05782\ttest-rmse:0.07841\n",
      "[48]\ttrain-rmse:0.05758\ttest-rmse:0.07841\n",
      "[49]\ttrain-rmse:0.05740\ttest-rmse:0.07838\n",
      "[50]\ttrain-rmse:0.05715\ttest-rmse:0.07836\n",
      "[51]\ttrain-rmse:0.05700\ttest-rmse:0.07842\n",
      "[52]\ttrain-rmse:0.05686\ttest-rmse:0.07850\n",
      "[53]\ttrain-rmse:0.05672\ttest-rmse:0.07842\n",
      "[54]\ttrain-rmse:0.05658\ttest-rmse:0.07843\n",
      "[55]\ttrain-rmse:0.05630\ttest-rmse:0.07843\n",
      "[56]\ttrain-rmse:0.05613\ttest-rmse:0.07839\n",
      "[57]\ttrain-rmse:0.05602\ttest-rmse:0.07840\n",
      "[58]\ttrain-rmse:0.05590\ttest-rmse:0.07841\n",
      "[59]\ttrain-rmse:0.05579\ttest-rmse:0.07842\n"
     ]
    }
   ],
   "source": [
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "preds = np.zeros((test.shape[0], len(col)))\n",
    "\n",
    "for i, j in enumerate(col):\n",
    "    print('fit '+j)\n",
    "    model = XGBoost(comments_train, train_y[j], comments_val,val_y[j])\n",
    "    preds[:,i] = model.predict(xgb.DMatrix(comments_test), ntree_limit = model.best_ntree_limit)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##慢慢慢\n",
    "labels=pd.read_csv('test_labels.csv')\n",
    "labels=np.array(labels.iloc[:,1:])\n",
    "sum_labels=np.sum(labels,axis=1)\n",
    "idx=sum_labels>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63978, 6), (63978, 6))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_consider=preds[idx]\n",
    "labels_consider= labels[idx]\n",
    "preds_consider.shape,labels_consider.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9413375603198052"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scores=[]\n",
    "for i in range(6):\n",
    "    scores.append(roc_auc_score(labels_consider[:,i],preds_consider[:,i]))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
